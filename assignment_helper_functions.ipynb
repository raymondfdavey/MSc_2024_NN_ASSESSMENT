{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saved DF structure\n",
    "'''\n",
    "{0.1: {'seeds':random_seeds,\n",
    "        'av_train_losses': [list of av train loss per epoch across the 5 runs len = [1,50],\n",
    "        'av_val_losses': [list of av val loss per epoch across the 5 runs len = [1,50],\n",
    "        'av_train_acc':[list of av train acc per epoch across the 5 runs len = [1,50],\n",
    "        'av_val_acc':[list of av val acc per epoch across the 5 runs len = [1,50],\n",
    "        'all_train_losses':[epoch_train_losses_by_run, shape is [5, 50]],\n",
    "        'all_val_losses':[ epoch_val_losses_by_run, shape is [5, 50]],\n",
    "        'all_train_accuracies':[epoch_train_accuracies_by_run, shape is [5, 50]],\n",
    "        'all_val_accuracies':[epoch_val_accuracies_by_run], shape is [5, 50]},\n",
    "0.01: {'seeds':random_seeds,\n",
    "        'av_train_losses': average_train_losses,\n",
    "        'av_val_losses': average_val_losses,\n",
    "        'av_train_acc': average_train_accuracies,\n",
    "        'av_val_acc': average_val_accuracies,\n",
    "        'all_train_losses':epoch_train_losses_by_run,\n",
    "        'all_val_losses': epoch_val_losses_by_run,\n",
    "        'all_train_accuracies': epoch_train_accuracies_by_run,\n",
    "        'all_val_accuracies': epoch_val_accuracies_by_run},\n",
    "        \n",
    "        ....}\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "# 1. imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import json\n",
    "import importlib\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    from IPython import get_ipython\n",
    "    if 'IPKernelApp' not in get_ipython().config:  # Not in a notebook\n",
    "        from tqdm import tqdm\n",
    "    else:  # In a notebook\n",
    "        from tqdm.notebook import tqdm\n",
    "except ImportError:  # IPython is not installed\n",
    "    from tqdm import tqdm\n",
    "import utils\n",
    "from utils import *\n",
    "\n",
    "# importlib.reload(utils)\n",
    "\n",
    "\n",
    "# 2. set up for using GPU if available (with printed confirmation)  \n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# 3. checking environment \n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "print(f\"IN_COLAB= {IN_COLAB}\")\n",
    "\n",
    "# 4. get the data for the task (for baseline, no transforms applied, simple train/test split used)\n",
    "# This is the equivalent of building an instance of the pytorch 'Dataset' class using the CIFAR dataset \n",
    "# Each dataset can be indexed into and each individual sample is a tuple of the form (image, target) where target is index of the target class ref https://pytorch.org/vision/stable/generated/torchvision.datasets.CIFAR10.html#torchvision.datasets.CIFAR10.\n",
    "# a simple train/test split \n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform)\n",
    "\n",
    "num_validation_samples = 5000\n",
    "num_train_samples = len(train_data) - num_validation_samples\n",
    "\n",
    "train_data, val_data = random_split(train_data, [num_train_samples, num_validation_samples])\n",
    "\n",
    "print(len(train_data)) # 50000 training egs  \n",
    "print(len(val_data)) # 10000 test egs\n",
    "print(len(test_data)) # 10000 test egs\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EX 1\n",
    "# 1.1 - Use average performance of each LR to plot training and validation data for each LR\n",
    "# 1.2 - plot average performance of a model using learning rate scheduler\n",
    "\n",
    "# 1.3 - using LR scheduler model AND best performing non-LR scheduled model COMPARE THEM\n",
    "    # - PLOT comparison of their train/validation gaps\n",
    "    # - COMPARE test performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 1.1 - Diff Learning rates\n",
    "\n",
    "num_epochs = 35\n",
    "random_seeds = list(range(5))\n",
    "learning_rates_for_experiment = [0.1, 0.01, 0.001, 0.0001]\n",
    "averaged_results = {lr:{} for lr in learning_rates_for_experiment}\n",
    "path_to_save = f'./run_data/learning_rates/corrected_lr_data_{num_epochs}_epochs.json'\n",
    "path_to_load = f'./run_data//learning_rates/corrected_lr_data_{num_epochs}_epochs.json'\n",
    "save_experiment = True\n",
    "\n",
    "for learning_rate in learning_rates_for_experiment:\n",
    "    print('LR: ', learning_rate) \n",
    "    epoch_train_losses_by_run = []\n",
    "    epoch_val_losses_by_run = []\n",
    "    epoch_train_accuracies_by_run = []\n",
    "    epoch_val_accuracies_by_run = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    reports = []\n",
    "       \n",
    "    for random_seed in random_seeds:\n",
    "        print('lr: ', learning_rate) \n",
    "        print('seed:', random_seed)\n",
    "        model = BaselineNet(random_seed).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimiser = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        model, train_epoch_losses, train_epoch_accuracy, val_epoch_losses, val_epoch_accuracy, _,_ = run_training_and_validation(model, device, learning_rate, num_epochs, criterion, optimiser, train_dataloader, val_dataloader, manual_lr_schedule=False)\n",
    "        epoch_train_losses_by_run.append(train_epoch_losses)\n",
    "        epoch_val_losses_by_run.append(val_epoch_losses)\n",
    "        epoch_train_accuracies_by_run.append(train_epoch_accuracy)\n",
    "        epoch_val_accuracies_by_run.append(val_epoch_accuracy)\n",
    "        \n",
    "        test_loss, test_accuracy, report = run_testing(model, device, criterion, test_dataloader)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        reports.append(report)\n",
    "    \n",
    "    average_train_losses = [sum(epoch_losses) / len(epoch_losses) for epoch_losses in zip(*epoch_train_losses_by_run)]\n",
    "    average_val_losses = [sum(epoch_losses) / len(epoch_losses) for epoch_losses in zip(*epoch_val_losses_by_run)]\n",
    "    average_train_accuracies = [sum(epoch_accuracies) / len(epoch_accuracies) for epoch_accuracies in zip(*epoch_train_accuracies_by_run)]\n",
    "    average_val_accuracies =  [sum(epoch_accuracies) / len(epoch_accuracies) for epoch_accuracies in zip(*epoch_val_accuracies_by_run)]\n",
    "    \n",
    "    average_test_loss = sum(test_losses)/len(test_losses)\n",
    "    average_test_accuracy = sum(test_accuracies)/len(test_accuracies)\n",
    "    \n",
    "    averaged_results[learning_rate] = {'seeds':random_seeds,\n",
    "                                       'av_train_losses': average_train_losses,\n",
    "                                       'av_val_losses': average_val_losses,\n",
    "                                       'av_train_acc': average_train_accuracies,\n",
    "                                       'av_val_acc': average_val_accuracies,\n",
    "                                       'all_train_losses':epoch_train_losses_by_run,\n",
    "                                       'all_val_losses': epoch_val_losses_by_run,\n",
    "                                       'all_train_accuracies': epoch_train_accuracies_by_run,\n",
    "                                       'all_val_accuracies': epoch_val_accuracies_by_run,\n",
    "                                       'all_test_losses':test_losses, \n",
    "                                       'all_test_accuracies':test_accuracies,\n",
    "                                       'av_test_loss': average_test_loss,\n",
    "                                       'av_test_accuracy':average_test_accuracy}\n",
    "if save_experiment:\n",
    "    with open(path_to_save, 'w') as file:\n",
    "        json.dump(averaged_results, file, indent=4)  # 'indent' makes the output formatted and easier to read\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import display_accuracy_heatmap, plot_all_models_performance_from_disk\n",
    "\n",
    "# # visualise results\n",
    "# results_path = 'run_data/lr_data_35_epochs.json'\n",
    "# display_accuracy_heatmap(results_path)\n",
    "# plot_all_models_performance_from_disk(results_path, enforce_axis_range=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1.2 - LR decay\n",
    "def adjust_learning_rate(optimiser, epoch, initial_lr=0.15, decay_rate=0.25):    \n",
    "    new_lr = initial_lr / (1 + decay_rate *epoch)\n",
    "    for param_group in optimiser.param_groups:\n",
    "        param_group['lr'] = new_lr\n",
    "    print('LR:',new_lr)\n",
    "    return optimiser\n",
    "\n",
    "num_epochs = 50\n",
    "learning_rate = 0.15\n",
    "\n",
    "random_seeds = list(range(5))\n",
    "decay_rate = 0.25\n",
    "averaged_results = {decay_rate:{}}\n",
    "path_to_save = f'./run_data/lr_decay/corrected_decaying_lr_just_decay_data_{num_epochs}_epochs_init_lr_0_15dr_0_25.json'\n",
    "path_to_load = f'./run_data/lr_decay/corrected_decaying_lr_just_decay_data_{num_epochs}_epochs_init_lr_0_15dr_0_25.json'\n",
    "save_experiment = True\n",
    "\n",
    "  \n",
    "epoch_train_losses_by_run = []\n",
    "epoch_val_losses_by_run = []\n",
    "epoch_train_accuracies_by_run = []\n",
    "epoch_val_accuracies_by_run = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "reports = []\n",
    "    \n",
    "for random_seed in random_seeds:\n",
    "    print('DECAY: ', decay_rate)\n",
    "    print('seed:', random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "\n",
    "    model = BaselineNet().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimiser = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    model,train_epoch_losses, train_epoch_accuracy, val_epoch_losses, val_epoch_accuracy, train_report,val_report = run_training_and_validation(model, device, learning_rate, num_epochs, criterion, optimiser, train_dataloader, val_dataloader, manual_lr_schedule=True, scheduler_func=adjust_learning_rate, plot=True)\n",
    "    epoch_train_losses_by_run.append(train_epoch_losses)\n",
    "    epoch_val_losses_by_run.append(val_epoch_losses)\n",
    "    epoch_train_accuracies_by_run.append(train_epoch_accuracy)\n",
    "    epoch_val_accuracies_by_run.append(val_epoch_accuracy)\n",
    "    \n",
    "    test_loss, test_accuracy, report = run_testing(model, device, criterion, test_dataloader)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    reports.append(report)\n",
    "\n",
    "    \n",
    "    average_train_losses = [sum(epoch_losses) / len(epoch_losses) for epoch_losses in zip(*epoch_train_losses_by_run)]\n",
    "    average_val_losses = [sum(epoch_losses) / len(epoch_losses) for epoch_losses in zip(*epoch_val_losses_by_run)]\n",
    "    average_train_accuracies = [sum(epoch_accuracies) / len(epoch_accuracies) for epoch_accuracies in zip(*epoch_train_accuracies_by_run)]\n",
    "    average_val_accuracies =  [sum(epoch_accuracies) / len(epoch_accuracies) for epoch_accuracies in zip(*epoch_val_accuracies_by_run)]\n",
    "    average_test_loss = sum(test_losses)/len(test_losses)\n",
    "    average_test_accuracy = sum(test_accuracies)/len(test_accuracies)\n",
    "    \n",
    "    averaged_results[decay_rate] = {'seeds':random_seeds,\n",
    "                                       'av_train_losses': average_train_losses,\n",
    "                                       'av_val_losses': average_val_losses,\n",
    "                                       'av_train_acc': average_train_accuracies,\n",
    "                                       'av_val_acc': average_val_accuracies,\n",
    "                                       'all_train_losses':epoch_train_losses_by_run,\n",
    "                                       'all_val_losses': epoch_val_losses_by_run,\n",
    "                                       'all_train_accuracies': epoch_train_accuracies_by_run,\n",
    "                                       'all_val_accuracies': epoch_val_accuracies_by_run,\n",
    "                                       'all_test_losses':test_losses, \n",
    "                                       'all_test_accuracies':test_accuracies,\n",
    "                                       'av_test_loss': average_test_loss,\n",
    "                                       'av_test_accuracy':average_test_accuracy}\n",
    "    \n",
    "    plot_single_train_val_smoothed(average_train_losses,average_val_losses,average_train_accuracies,average_val_accuracies, num_epochs, smoothing_window=5, title=f'DECAY: {decay_rate}')\n",
    "    \n",
    "if save_experiment:\n",
    "    with open(path_to_save, 'w') as file:\n",
    "        json.dump(averaged_results, file, indent=4)  # 'indent' makes the output formatted and easier to read\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1.2 - LR decay\n",
    "def adjust_learning_rate(optimiser, epoch, initial_lr=0.1, decay_rate=0.75):    \n",
    "    new_lr = initial_lr / (1 + decay_rate *epoch)\n",
    "    for param_group in optimiser.param_groups:\n",
    "        param_group['lr'] = new_lr\n",
    "    print('LR:',new_lr)\n",
    "    return optimiser\n",
    "\n",
    "num_epochs = 50\n",
    "learning_rate = 0.15\n",
    "\n",
    "random_seeds = list(range(5))\n",
    "decay_rate = 0.25\n",
    "averaged_results = {decay_rate:{}}\n",
    "path_to_save = f'./run_data/lr_decay/corrected_decaying_lr_just_decay_data_{num_epochs}_epochs_init_lr_0_1dr_0_75.json'\n",
    "path_to_load = f'./run_data/lr_decay/corrected_decaying_lr_just_decay_data_{num_epochs}_epochs_init_lr_0_1dr_0_75.json'\n",
    "save_experiment = True\n",
    "\n",
    "  \n",
    "epoch_train_losses_by_run = []\n",
    "epoch_val_losses_by_run = []\n",
    "epoch_train_accuracies_by_run = []\n",
    "epoch_val_accuracies_by_run = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "reports = []\n",
    "    \n",
    "for random_seed in random_seeds:\n",
    "    print('DECAY: ', decay_rate)\n",
    "    print('seed:', random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "\n",
    "    model = BaselineNet().to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimiser = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    model,train_epoch_losses, train_epoch_accuracy, val_epoch_losses, val_epoch_accuracy, train_report,val_report = run_training_and_validation(model, device, learning_rate, num_epochs, criterion, optimiser, train_dataloader, val_dataloader, manual_lr_schedule=True, scheduler_func=adjust_learning_rate, plot=True)\n",
    "    epoch_train_losses_by_run.append(train_epoch_losses)\n",
    "    epoch_val_losses_by_run.append(val_epoch_losses)\n",
    "    epoch_train_accuracies_by_run.append(train_epoch_accuracy)\n",
    "    epoch_val_accuracies_by_run.append(val_epoch_accuracy)\n",
    "    \n",
    "    test_loss, test_accuracy, report = run_testing(model, device, criterion, test_dataloader)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    reports.append(report)\n",
    "\n",
    "    \n",
    "    average_train_losses = [sum(epoch_losses) / len(epoch_losses) for epoch_losses in zip(*epoch_train_losses_by_run)]\n",
    "    average_val_losses = [sum(epoch_losses) / len(epoch_losses) for epoch_losses in zip(*epoch_val_losses_by_run)]\n",
    "    average_train_accuracies = [sum(epoch_accuracies) / len(epoch_accuracies) for epoch_accuracies in zip(*epoch_train_accuracies_by_run)]\n",
    "    average_val_accuracies =  [sum(epoch_accuracies) / len(epoch_accuracies) for epoch_accuracies in zip(*epoch_val_accuracies_by_run)]\n",
    "    average_test_loss = sum(test_losses)/len(test_losses)\n",
    "    average_test_accuracy = sum(test_accuracies)/len(test_accuracies)\n",
    "    \n",
    "    averaged_results[decay_rate] = {'seeds':random_seeds,\n",
    "                                       'av_train_losses': average_train_losses,\n",
    "                                       'av_val_losses': average_val_losses,\n",
    "                                       'av_train_acc': average_train_accuracies,\n",
    "                                       'av_val_acc': average_val_accuracies,\n",
    "                                       'all_train_losses':epoch_train_losses_by_run,\n",
    "                                       'all_val_losses': epoch_val_losses_by_run,\n",
    "                                       'all_train_accuracies': epoch_train_accuracies_by_run,\n",
    "                                       'all_val_accuracies': epoch_val_accuracies_by_run,\n",
    "                                       'all_test_losses':test_losses, \n",
    "                                       'all_test_accuracies':test_accuracies,\n",
    "                                       'av_test_loss': average_test_loss,\n",
    "                                       'av_test_accuracy':average_test_accuracy}\n",
    "    \n",
    "    plot_single_train_val_smoothed(average_train_losses,average_val_losses,average_train_accuracies,average_val_accuracies, num_epochs, smoothing_window=5, title=f'DECAY: {decay_rate}')\n",
    "    \n",
    "if save_experiment:\n",
    "    with open(path_to_save, 'w') as file:\n",
    "        json.dump(averaged_results, file, indent=4)  # 'indent' makes the output formatted and easier to read\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp 2 prep\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform)\n",
    "\n",
    "num_validation_samples = 25000\n",
    "num_train_samples = len(train_data) - num_validation_samples\n",
    "train_data, val_data = random_split(train_data, [num_train_samples, num_validation_samples])\n",
    "\n",
    "print(len(train_data)) # 50000 training egs  \n",
    "print(len(val_data)) # 10000 test egs\n",
    "print(len(test_data)) # 10000 test egs\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT 2\n",
    "# 2.1.1 - plot VAL/TRAINING gap for each drop out rate\n",
    "# 2.1.2- evaluate on test set for each too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100] - Train Loss: 1.2255, Acc: 0.5649 | Val Loss: 1.2030, Acc: 0.5681\n",
      "Epoch [22/100] - Train Loss: 1.1973, Acc: 0.5745 | Val Loss: 1.1605, Acc: 0.5839\n",
      "Epoch [23/100] - Train Loss: 1.1808, Acc: 0.5774 | Val Loss: 1.1439, Acc: 0.5883\n",
      "Epoch [24/100] - Train Loss: 1.1542, Acc: 0.5888 | Val Loss: 1.1254, Acc: 0.6011\n",
      "Epoch [25/100] - Train Loss: 1.1326, Acc: 0.5998 | Val Loss: 1.1178, Acc: 0.6028\n",
      "Epoch [26/100] - Train Loss: 1.1065, Acc: 0.6059 | Val Loss: 1.0942, Acc: 0.6062\n",
      "Epoch [27/100] - Train Loss: 1.0838, Acc: 0.6176 | Val Loss: 1.0893, Acc: 0.6095\n",
      "Epoch [28/100] - Train Loss: 1.0629, Acc: 0.6254 | Val Loss: 1.0940, Acc: 0.6140\n",
      "Epoch [29/100] - Train Loss: 1.0397, Acc: 0.6303 | Val Loss: 1.0218, Acc: 0.6419\n",
      "Epoch [30/100] - Train Loss: 1.0151, Acc: 0.6436 | Val Loss: 1.0280, Acc: 0.6326\n",
      "Epoch [31/100] - Train Loss: 0.9997, Acc: 0.6476 | Val Loss: 1.0114, Acc: 0.6402\n",
      "Epoch [32/100] - Train Loss: 0.9816, Acc: 0.6521 | Val Loss: 1.0172, Acc: 0.6421\n",
      "Epoch [33/100] - Train Loss: 0.9582, Acc: 0.6613 | Val Loss: 1.0061, Acc: 0.6369\n",
      "Epoch [34/100] - Train Loss: 0.9417, Acc: 0.6668 | Val Loss: 0.9881, Acc: 0.6508\n",
      "Epoch [35/100] - Train Loss: 0.9229, Acc: 0.6763 | Val Loss: 0.9625, Acc: 0.6573\n",
      "Epoch [36/100] - Train Loss: 0.9001, Acc: 0.6854 | Val Loss: 0.9706, Acc: 0.6582\n",
      "Epoch [37/100] - Train Loss: 0.8799, Acc: 0.6912 | Val Loss: 0.9444, Acc: 0.6649\n",
      "Epoch [38/100] - Train Loss: 0.8659, Acc: 0.6969 | Val Loss: 0.9499, Acc: 0.6649\n",
      "Epoch [39/100] - Train Loss: 0.8493, Acc: 0.7022 | Val Loss: 0.9325, Acc: 0.6707\n",
      "Epoch [40/100] - Train Loss: 0.8283, Acc: 0.7087 | Val Loss: 0.9965, Acc: 0.6542\n",
      "Epoch [41/100] - Train Loss: 0.8092, Acc: 0.7151 | Val Loss: 0.9062, Acc: 0.6804\n",
      "Epoch [42/100] - Train Loss: 0.7933, Acc: 0.7183 | Val Loss: 0.8996, Acc: 0.6815\n",
      "Epoch [43/100] - Train Loss: 0.7746, Acc: 0.7279 | Val Loss: 0.8865, Acc: 0.6884\n",
      "Epoch [44/100] - Train Loss: 0.7577, Acc: 0.7345 | Val Loss: 0.9033, Acc: 0.6826\n",
      "Epoch [45/100] - Train Loss: 0.7368, Acc: 0.7414 | Val Loss: 0.9159, Acc: 0.6796\n",
      "Epoch [46/100] - Train Loss: 0.7256, Acc: 0.7451 | Val Loss: 0.8767, Acc: 0.6936\n",
      "Epoch [47/100] - Train Loss: 0.7098, Acc: 0.7507 | Val Loss: 0.8731, Acc: 0.6941\n",
      "Epoch [48/100] - Train Loss: 0.6993, Acc: 0.7570 | Val Loss: 0.9075, Acc: 0.6812\n",
      "Epoch [49/100] - Train Loss: 0.6770, Acc: 0.7640 | Val Loss: 0.8702, Acc: 0.6976\n",
      "Epoch [50/100] - Train Loss: 0.6629, Acc: 0.7664 | Val Loss: 0.9054, Acc: 0.6868\n",
      "Epoch [51/100] - Train Loss: 0.6460, Acc: 0.7739 | Val Loss: 0.9328, Acc: 0.6805\n",
      "Epoch [52/100] - Train Loss: 0.6334, Acc: 0.7756 | Val Loss: 0.8913, Acc: 0.6957\n",
      "Epoch [53/100] - Train Loss: 0.6185, Acc: 0.7840 | Val Loss: 0.8672, Acc: 0.7022\n",
      "Epoch [54/100] - Train Loss: 0.6017, Acc: 0.7897 | Val Loss: 0.8780, Acc: 0.6963\n",
      "Epoch [55/100] - Train Loss: 0.5889, Acc: 0.7939 | Val Loss: 0.9191, Acc: 0.6890\n",
      "Epoch [56/100] - Train Loss: 0.5701, Acc: 0.7986 | Val Loss: 0.8813, Acc: 0.7054\n",
      "Epoch [57/100] - Train Loss: 0.5594, Acc: 0.8035 | Val Loss: 0.8766, Acc: 0.7038\n",
      "Epoch [58/100] - Train Loss: 0.5401, Acc: 0.8092 | Val Loss: 0.9125, Acc: 0.7017\n",
      "Epoch [59/100] - Train Loss: 0.5247, Acc: 0.8143 | Val Loss: 0.9274, Acc: 0.6932\n",
      "Epoch [60/100] - Train Loss: 0.5090, Acc: 0.8209 | Val Loss: 0.9161, Acc: 0.6923\n",
      "Epoch [61/100] - Train Loss: 0.4978, Acc: 0.8233 | Val Loss: 0.9351, Acc: 0.6954\n",
      "Epoch [62/100] - Train Loss: 0.4834, Acc: 0.8302 | Val Loss: 0.9229, Acc: 0.7006\n",
      "Epoch [63/100] - Train Loss: 0.4703, Acc: 0.8330 | Val Loss: 0.8939, Acc: 0.7092\n",
      "Epoch [64/100] - Train Loss: 0.4546, Acc: 0.8381 | Val Loss: 0.9318, Acc: 0.7034\n",
      "Epoch [65/100] - Train Loss: 0.4374, Acc: 0.8444 | Val Loss: 0.9329, Acc: 0.6990\n",
      "Epoch [66/100] - Train Loss: 0.4317, Acc: 0.8472 | Val Loss: 0.9890, Acc: 0.6968\n",
      "Epoch [67/100] - Train Loss: 0.4179, Acc: 0.8521 | Val Loss: 0.9163, Acc: 0.7070\n",
      "Epoch [68/100] - Train Loss: 0.3988, Acc: 0.8601 | Val Loss: 0.9301, Acc: 0.7089\n",
      "Epoch [69/100] - Train Loss: 0.3880, Acc: 0.8596 | Val Loss: 0.9461, Acc: 0.7075\n",
      "Epoch [70/100] - Train Loss: 0.3775, Acc: 0.8649 | Val Loss: 1.0158, Acc: 0.6926\n",
      "Epoch [71/100] - Train Loss: 0.3677, Acc: 0.8699 | Val Loss: 0.9773, Acc: 0.7060\n",
      "Epoch [72/100] - Train Loss: 0.3522, Acc: 0.8751 | Val Loss: 0.9802, Acc: 0.7106\n",
      "Epoch [73/100] - Train Loss: 0.3484, Acc: 0.8773 | Val Loss: 0.9327, Acc: 0.7128\n",
      "Epoch [74/100] - Train Loss: 0.3347, Acc: 0.8805 | Val Loss: 0.9885, Acc: 0.7098\n",
      "Epoch [75/100] - Train Loss: 0.3212, Acc: 0.8853 | Val Loss: 0.9713, Acc: 0.7132\n",
      "Epoch [76/100] - Train Loss: 0.3102, Acc: 0.8873 | Val Loss: 1.0512, Acc: 0.6972\n",
      "Epoch [77/100] - Train Loss: 0.2995, Acc: 0.8939 | Val Loss: 1.0163, Acc: 0.7098\n",
      "Epoch [78/100] - Train Loss: 0.2963, Acc: 0.8926 | Val Loss: 1.0538, Acc: 0.7055\n",
      "Epoch [79/100] - Train Loss: 0.2813, Acc: 0.8985 | Val Loss: 1.1067, Acc: 0.6995\n",
      "Epoch [80/100] - Train Loss: 0.2700, Acc: 0.9049 | Val Loss: 1.0332, Acc: 0.7069\n",
      "Epoch [81/100] - Train Loss: 0.2578, Acc: 0.9078 | Val Loss: 1.0848, Acc: 0.7109\n",
      "Epoch [82/100] - Train Loss: 0.2585, Acc: 0.9084 | Val Loss: 1.0615, Acc: 0.7147\n",
      "Epoch [83/100] - Train Loss: 0.2466, Acc: 0.9119 | Val Loss: 1.0843, Acc: 0.7009\n",
      "Epoch [84/100] - Train Loss: 0.2422, Acc: 0.9135 | Val Loss: 1.0828, Acc: 0.7156\n",
      "Epoch [85/100] - Train Loss: 0.2347, Acc: 0.9157 | Val Loss: 1.0873, Acc: 0.7092\n",
      "Epoch [86/100] - Train Loss: 0.2220, Acc: 0.9226 | Val Loss: 1.0981, Acc: 0.7083\n",
      "Epoch [87/100] - Train Loss: 0.2203, Acc: 0.9221 | Val Loss: 1.1665, Acc: 0.7083\n",
      "Epoch [88/100] - Train Loss: 0.2061, Acc: 0.9281 | Val Loss: 1.1849, Acc: 0.7074\n",
      "Epoch [89/100] - Train Loss: 0.2037, Acc: 0.9278 | Val Loss: 1.2314, Acc: 0.6960\n",
      "Epoch [90/100] - Train Loss: 0.2021, Acc: 0.9283 | Val Loss: 1.1720, Acc: 0.7045\n",
      "Epoch [91/100] - Train Loss: 0.1950, Acc: 0.9307 | Val Loss: 1.1624, Acc: 0.7121\n",
      "Epoch [92/100] - Train Loss: 0.1851, Acc: 0.9343 | Val Loss: 1.1663, Acc: 0.7119\n",
      "Epoch [93/100] - Train Loss: 0.1771, Acc: 0.9386 | Val Loss: 1.1856, Acc: 0.7116\n",
      "Epoch [94/100] - Train Loss: 0.1752, Acc: 0.9391 | Val Loss: 1.2083, Acc: 0.7130\n",
      "Epoch [95/100] - Train Loss: 0.1734, Acc: 0.9389 | Val Loss: 1.1706, Acc: 0.7107\n",
      "Epoch [96/100] - Train Loss: 0.1654, Acc: 0.9415 | Val Loss: 1.2832, Acc: 0.7053\n",
      "Epoch [97/100] - Train Loss: 0.1558, Acc: 0.9467 | Val Loss: 1.2229, Acc: 0.7162\n",
      "Epoch [98/100] - Train Loss: 0.1548, Acc: 0.9464 | Val Loss: 1.2700, Acc: 0.7114\n",
      "Epoch [99/100] - Train Loss: 0.1472, Acc: 0.9473 | Val Loss: 1.2101, Acc: 0.7171\n",
      "Epoch [100/100] - Train Loss: 0.1470, Acc: 0.9481 | Val Loss: 1.4576, Acc: 0.6855\n",
      "TESTING COMPLETE!!\n",
      "Test Loss: 1.4528, Test Acc: 0.6854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       plane       0.78      0.69      0.73      1000\n",
      "         car       0.85      0.80      0.82      1000\n",
      "        bird       0.47      0.71      0.57      1000\n",
      "         cat       0.57      0.42      0.48      1000\n",
      "        deer       0.58      0.71      0.64      1000\n",
      "         dog       0.70      0.52      0.59      1000\n",
      "        frog       0.61      0.86      0.72      1000\n",
      "       horse       0.90      0.57      0.70      1000\n",
      "        ship       0.80      0.85      0.82      1000\n",
      "       truck       0.83      0.73      0.78      1000\n",
      "\n",
      "    accuracy                           0.69     10000\n",
      "   macro avg       0.71      0.69      0.69     10000\n",
      "weighted avg       0.71      0.69      0.69     10000\n",
      "\n",
      "DR:  0.4\n",
      "seed: 1\n",
      "Epoch [1/100] - Train Loss: 2.2920, Acc: 0.1557 | Val Loss: 2.2710, Acc: 0.2256\n",
      "Epoch [2/100] - Train Loss: 2.1833, Acc: 0.2217 | Val Loss: 2.0682, Acc: 0.2649\n",
      "Epoch [3/100] - Train Loss: 2.0117, Acc: 0.2783 | Val Loss: 1.8963, Acc: 0.3171\n",
      "Epoch [4/100] - Train Loss: 1.8756, Acc: 0.3247 | Val Loss: 1.7840, Acc: 0.3559\n",
      "Epoch [5/100] - Train Loss: 1.7712, Acc: 0.3593 | Val Loss: 1.6738, Acc: 0.3955\n",
      "Epoch [6/100] - Train Loss: 1.6901, Acc: 0.3862 | Val Loss: 1.6242, Acc: 0.4094\n",
      "Epoch [7/100] - Train Loss: 1.6306, Acc: 0.4069 | Val Loss: 1.5689, Acc: 0.4320\n",
      "Epoch [8/100] - Train Loss: 1.5743, Acc: 0.4304 | Val Loss: 1.5833, Acc: 0.4305\n",
      "Epoch [9/100] - Train Loss: 1.5374, Acc: 0.4446 | Val Loss: 1.4785, Acc: 0.4629\n",
      "Epoch [10/100] - Train Loss: 1.4947, Acc: 0.4592 | Val Loss: 1.5262, Acc: 0.4512\n",
      "Epoch [11/100] - Train Loss: 1.4601, Acc: 0.4770 | Val Loss: 1.4402, Acc: 0.4796\n",
      "Epoch [12/100] - Train Loss: 1.4277, Acc: 0.4854 | Val Loss: 1.3808, Acc: 0.5022\n",
      "Epoch [13/100] - Train Loss: 1.3961, Acc: 0.4953 | Val Loss: 1.3382, Acc: 0.5138\n",
      "Epoch [14/100] - Train Loss: 1.3752, Acc: 0.5050 | Val Loss: 1.3225, Acc: 0.5212\n",
      "Epoch [15/100] - Train Loss: 1.3526, Acc: 0.5103 | Val Loss: 1.3006, Acc: 0.5278\n",
      "Epoch [16/100] - Train Loss: 1.3260, Acc: 0.5248 | Val Loss: 1.3275, Acc: 0.5259\n",
      "Epoch [17/100] - Train Loss: 1.2968, Acc: 0.5326 | Val Loss: 1.2453, Acc: 0.5508\n",
      "Epoch [18/100] - Train Loss: 1.2687, Acc: 0.5459 | Val Loss: 1.2280, Acc: 0.5563\n",
      "Epoch [19/100] - Train Loss: 1.2471, Acc: 0.5528 | Val Loss: 1.2577, Acc: 0.5467\n",
      "Epoch [20/100] - Train Loss: 1.2249, Acc: 0.5611 | Val Loss: 1.2450, Acc: 0.5516\n",
      "Epoch [21/100] - Train Loss: 1.2048, Acc: 0.5697 | Val Loss: 1.1855, Acc: 0.5754\n",
      "Epoch [22/100] - Train Loss: 1.1795, Acc: 0.5801 | Val Loss: 1.1580, Acc: 0.5905\n",
      "Epoch [23/100] - Train Loss: 1.1564, Acc: 0.5902 | Val Loss: 1.1277, Acc: 0.5943\n",
      "Epoch [24/100] - Train Loss: 1.1351, Acc: 0.5956 | Val Loss: 1.1232, Acc: 0.5984\n",
      "Epoch [25/100] - Train Loss: 1.1056, Acc: 0.6105 | Val Loss: 1.1358, Acc: 0.5929\n",
      "Epoch [26/100] - Train Loss: 1.0872, Acc: 0.6162 | Val Loss: 1.0837, Acc: 0.6189\n",
      "Epoch [27/100] - Train Loss: 1.0627, Acc: 0.6196 | Val Loss: 1.0769, Acc: 0.6153\n",
      "Epoch [28/100] - Train Loss: 1.0411, Acc: 0.6276 | Val Loss: 1.0869, Acc: 0.6135\n",
      "Epoch [29/100] - Train Loss: 1.0196, Acc: 0.6390 | Val Loss: 1.0769, Acc: 0.6171\n",
      "Epoch [30/100] - Train Loss: 1.0047, Acc: 0.6452 | Val Loss: 1.0540, Acc: 0.6270\n",
      "Epoch [31/100] - Train Loss: 0.9789, Acc: 0.6538 | Val Loss: 1.0791, Acc: 0.6211\n",
      "Epoch [32/100] - Train Loss: 0.9627, Acc: 0.6572 | Val Loss: 1.0837, Acc: 0.6213\n",
      "Epoch [33/100] - Train Loss: 0.9403, Acc: 0.6659 | Val Loss: 0.9756, Acc: 0.6547\n",
      "Epoch [34/100] - Train Loss: 0.9250, Acc: 0.6737 | Val Loss: 1.0043, Acc: 0.6477\n",
      "Epoch [35/100] - Train Loss: 0.9086, Acc: 0.6771 | Val Loss: 0.9582, Acc: 0.6617\n",
      "Epoch [36/100] - Train Loss: 0.8816, Acc: 0.6903 | Val Loss: 0.9689, Acc: 0.6588\n",
      "Epoch [37/100] - Train Loss: 0.8656, Acc: 0.6923 | Val Loss: 0.9300, Acc: 0.6719\n",
      "Epoch [38/100] - Train Loss: 0.8464, Acc: 0.7010 | Val Loss: 0.9402, Acc: 0.6689\n",
      "Epoch [39/100] - Train Loss: 0.8306, Acc: 0.7058 | Val Loss: 0.9403, Acc: 0.6707\n",
      "Epoch [40/100] - Train Loss: 0.8148, Acc: 0.7109 | Val Loss: 0.9451, Acc: 0.6681\n",
      "Epoch [41/100] - Train Loss: 0.7935, Acc: 0.7204 | Val Loss: 0.8932, Acc: 0.6869\n",
      "Epoch [42/100] - Train Loss: 0.7796, Acc: 0.7227 | Val Loss: 0.9082, Acc: 0.6814\n",
      "Epoch [43/100] - Train Loss: 0.7585, Acc: 0.7314 | Val Loss: 0.8969, Acc: 0.6833\n",
      "Epoch [44/100] - Train Loss: 0.7471, Acc: 0.7359 | Val Loss: 0.9252, Acc: 0.6773\n",
      "Epoch [45/100] - Train Loss: 0.7295, Acc: 0.7429 | Val Loss: 0.9174, Acc: 0.6830\n",
      "Epoch [46/100] - Train Loss: 0.7126, Acc: 0.7492 | Val Loss: 0.9286, Acc: 0.6784\n",
      "Epoch [47/100] - Train Loss: 0.6956, Acc: 0.7539 | Val Loss: 0.9330, Acc: 0.6769\n",
      "Epoch [48/100] - Train Loss: 0.6776, Acc: 0.7615 | Val Loss: 0.8786, Acc: 0.6978\n",
      "Epoch [49/100] - Train Loss: 0.6663, Acc: 0.7647 | Val Loss: 0.8710, Acc: 0.7012\n",
      "Epoch [50/100] - Train Loss: 0.6456, Acc: 0.7713 | Val Loss: 0.8698, Acc: 0.6993\n",
      "Epoch [51/100] - Train Loss: 0.6280, Acc: 0.7791 | Val Loss: 0.8895, Acc: 0.6912\n",
      "Epoch [52/100] - Train Loss: 0.6167, Acc: 0.7806 | Val Loss: 0.9076, Acc: 0.6912\n",
      "Epoch [53/100] - Train Loss: 0.6035, Acc: 0.7808 | Val Loss: 0.8976, Acc: 0.6973\n",
      "Epoch [54/100] - Train Loss: 0.5808, Acc: 0.7932 | Val Loss: 0.8677, Acc: 0.7047\n",
      "Epoch [55/100] - Train Loss: 0.5691, Acc: 0.7983 | Val Loss: 0.9225, Acc: 0.6893\n",
      "Epoch [56/100] - Train Loss: 0.5483, Acc: 0.8079 | Val Loss: 0.8918, Acc: 0.7041\n",
      "Epoch [57/100] - Train Loss: 0.5345, Acc: 0.8109 | Val Loss: 0.8933, Acc: 0.7023\n",
      "Epoch [58/100] - Train Loss: 0.5269, Acc: 0.8146 | Val Loss: 0.9744, Acc: 0.6794\n",
      "Epoch [59/100] - Train Loss: 0.5082, Acc: 0.8189 | Val Loss: 0.9386, Acc: 0.6991\n",
      "Epoch [60/100] - Train Loss: 0.4919, Acc: 0.8272 | Val Loss: 0.9057, Acc: 0.7028\n",
      "Epoch [61/100] - Train Loss: 0.4827, Acc: 0.8260 | Val Loss: 0.8937, Acc: 0.7083\n",
      "Epoch [62/100] - Train Loss: 0.4685, Acc: 0.8338 | Val Loss: 0.9521, Acc: 0.6939\n",
      "Epoch [63/100] - Train Loss: 0.4565, Acc: 0.8362 | Val Loss: 0.9305, Acc: 0.7058\n",
      "Epoch [64/100] - Train Loss: 0.4387, Acc: 0.8443 | Val Loss: 0.9059, Acc: 0.7092\n",
      "Epoch [65/100] - Train Loss: 0.4277, Acc: 0.8475 | Val Loss: 0.9121, Acc: 0.7030\n",
      "Epoch [66/100] - Train Loss: 0.4112, Acc: 0.8520 | Val Loss: 0.9601, Acc: 0.7031\n",
      "Epoch [67/100] - Train Loss: 0.4016, Acc: 0.8580 | Val Loss: 0.9333, Acc: 0.7094\n",
      "Epoch [68/100] - Train Loss: 0.3934, Acc: 0.8590 | Val Loss: 0.9922, Acc: 0.6973\n",
      "Epoch [69/100] - Train Loss: 0.3798, Acc: 0.8655 | Val Loss: 0.9669, Acc: 0.7102\n",
      "Epoch [70/100] - Train Loss: 0.3658, Acc: 0.8688 | Val Loss: 0.9558, Acc: 0.7103\n",
      "Epoch [71/100] - Train Loss: 0.3476, Acc: 0.8770 | Val Loss: 0.9899, Acc: 0.7029\n",
      "Epoch [72/100] - Train Loss: 0.3423, Acc: 0.8786 | Val Loss: 0.9640, Acc: 0.7117\n",
      "Epoch [73/100] - Train Loss: 0.3263, Acc: 0.8857 | Val Loss: 0.9881, Acc: 0.7081\n",
      "Epoch [74/100] - Train Loss: 0.3256, Acc: 0.8859 | Val Loss: 1.0488, Acc: 0.6964\n",
      "Epoch [75/100] - Train Loss: 0.3080, Acc: 0.8901 | Val Loss: 1.0035, Acc: 0.7099\n",
      "Epoch [76/100] - Train Loss: 0.3009, Acc: 0.8943 | Val Loss: 1.0070, Acc: 0.7100\n",
      "Epoch [77/100] - Train Loss: 0.2869, Acc: 0.8985 | Val Loss: 1.0104, Acc: 0.7106\n",
      "Epoch [78/100] - Train Loss: 0.2774, Acc: 0.9016 | Val Loss: 1.0635, Acc: 0.7049\n",
      "Epoch [79/100] - Train Loss: 0.2701, Acc: 0.9036 | Val Loss: 1.0910, Acc: 0.7015\n",
      "Epoch [80/100] - Train Loss: 0.2669, Acc: 0.9040 | Val Loss: 1.1091, Acc: 0.7051\n",
      "Epoch [81/100] - Train Loss: 0.2547, Acc: 0.9088 | Val Loss: 1.0715, Acc: 0.7054\n",
      "Epoch [82/100] - Train Loss: 0.2423, Acc: 0.9145 | Val Loss: 1.1333, Acc: 0.6980\n",
      "Epoch [83/100] - Train Loss: 0.2347, Acc: 0.9162 | Val Loss: 1.1831, Acc: 0.7003\n",
      "Epoch [84/100] - Train Loss: 0.2298, Acc: 0.9192 | Val Loss: 1.1119, Acc: 0.7051\n",
      "Epoch [85/100] - Train Loss: 0.2235, Acc: 0.9224 | Val Loss: 1.2082, Acc: 0.6983\n",
      "Epoch [86/100] - Train Loss: 0.2161, Acc: 0.9229 | Val Loss: 1.1562, Acc: 0.7011\n",
      "Epoch [87/100] - Train Loss: 0.2081, Acc: 0.9269 | Val Loss: 1.2217, Acc: 0.6965\n",
      "Epoch [88/100] - Train Loss: 0.2031, Acc: 0.9295 | Val Loss: 1.1542, Acc: 0.7059\n",
      "Epoch [89/100] - Train Loss: 0.1976, Acc: 0.9301 | Val Loss: 1.2229, Acc: 0.7057\n",
      "Epoch [90/100] - Train Loss: 0.1900, Acc: 0.9328 | Val Loss: 1.1875, Acc: 0.7072\n",
      "Epoch [91/100] - Train Loss: 0.1882, Acc: 0.9348 | Val Loss: 1.1580, Acc: 0.7089\n",
      "Epoch [92/100] - Train Loss: 0.1794, Acc: 0.9375 | Val Loss: 1.2249, Acc: 0.7087\n",
      "Epoch [93/100] - Train Loss: 0.1741, Acc: 0.9384 | Val Loss: 1.2110, Acc: 0.7084\n",
      "Epoch [94/100] - Train Loss: 0.1747, Acc: 0.9375 | Val Loss: 1.5323, Acc: 0.6816\n",
      "Epoch [95/100] - Train Loss: 0.1649, Acc: 0.9414 | Val Loss: 1.2460, Acc: 0.7025\n",
      "Epoch [96/100] - Train Loss: 0.1574, Acc: 0.9443 | Val Loss: 1.2757, Acc: 0.7023\n",
      "Epoch [97/100] - Train Loss: 0.1509, Acc: 0.9475 | Val Loss: 1.2816, Acc: 0.7108\n",
      "Epoch [98/100] - Train Loss: 0.1566, Acc: 0.9463 | Val Loss: 1.2552, Acc: 0.7077\n",
      "Epoch [99/100] - Train Loss: 0.1498, Acc: 0.9465 | Val Loss: 1.2629, Acc: 0.7060\n",
      "Epoch [100/100] - Train Loss: 0.1409, Acc: 0.9499 | Val Loss: 1.3246, Acc: 0.7059\n",
      "TESTING COMPLETE!!\n",
      "Test Loss: 1.3087, Test Acc: 0.7118\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       plane       0.74      0.78      0.76      1000\n",
      "         car       0.83      0.82      0.83      1000\n",
      "        bird       0.63      0.60      0.61      1000\n",
      "         cat       0.49      0.59      0.53      1000\n",
      "        deer       0.75      0.57      0.65      1000\n",
      "         dog       0.57      0.63      0.59      1000\n",
      "        frog       0.78      0.77      0.78      1000\n",
      "       horse       0.76      0.75      0.76      1000\n",
      "        ship       0.84      0.82      0.83      1000\n",
      "       truck       0.79      0.79      0.79      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.71      0.71     10000\n",
      "weighted avg       0.72      0.71      0.71     10000\n",
      "\n",
      "DR:  0.4\n",
      "seed: 2\n",
      "Epoch [1/100] - Train Loss: 2.2971, Acc: 0.1330 | Val Loss: 2.2877, Acc: 0.2032\n",
      "Epoch [2/100] - Train Loss: 2.2439, Acc: 0.2050 | Val Loss: 2.1445, Acc: 0.2321\n",
      "Epoch [3/100] - Train Loss: 2.0698, Acc: 0.2509 | Val Loss: 1.9651, Acc: 0.2887\n",
      "Epoch [4/100] - Train Loss: 1.9447, Acc: 0.2941 | Val Loss: 1.8572, Acc: 0.3357\n",
      "Epoch [5/100] - Train Loss: 1.8383, Acc: 0.3370 | Val Loss: 1.7379, Acc: 0.3684\n",
      "Epoch [6/100] - Train Loss: 1.7238, Acc: 0.3760 | Val Loss: 1.6216, Acc: 0.4134\n",
      "Epoch [7/100] - Train Loss: 1.6305, Acc: 0.4055 | Val Loss: 1.5581, Acc: 0.4349\n",
      "Epoch [8/100] - Train Loss: 1.5622, Acc: 0.4362 | Val Loss: 1.4846, Acc: 0.4633\n",
      "Epoch [9/100] - Train Loss: 1.5158, Acc: 0.4502 | Val Loss: 1.4329, Acc: 0.4777\n",
      "Epoch [10/100] - Train Loss: 1.4720, Acc: 0.4652 | Val Loss: 1.5479, Acc: 0.4407\n",
      "Epoch [11/100] - Train Loss: 1.4388, Acc: 0.4780 | Val Loss: 1.3773, Acc: 0.4987\n",
      "Epoch [12/100] - Train Loss: 1.4084, Acc: 0.4906 | Val Loss: 1.3594, Acc: 0.5035\n",
      "Epoch [13/100] - Train Loss: 1.3755, Acc: 0.5029 | Val Loss: 1.3253, Acc: 0.5193\n",
      "Epoch [14/100] - Train Loss: 1.3543, Acc: 0.5105 | Val Loss: 1.3525, Acc: 0.5136\n",
      "Epoch [15/100] - Train Loss: 1.3271, Acc: 0.5226 | Val Loss: 1.2807, Acc: 0.5393\n",
      "Epoch [16/100] - Train Loss: 1.3017, Acc: 0.5327 | Val Loss: 1.2691, Acc: 0.5427\n",
      "Epoch [17/100] - Train Loss: 1.2780, Acc: 0.5389 | Val Loss: 1.2738, Acc: 0.5421\n",
      "Epoch [18/100] - Train Loss: 1.2575, Acc: 0.5527 | Val Loss: 1.2063, Acc: 0.5692\n",
      "Epoch [19/100] - Train Loss: 1.2333, Acc: 0.5580 | Val Loss: 1.1898, Acc: 0.5711\n",
      "Epoch [20/100] - Train Loss: 1.2147, Acc: 0.5638 | Val Loss: 1.2255, Acc: 0.5610\n",
      "Epoch [21/100] - Train Loss: 1.1935, Acc: 0.5722 | Val Loss: 1.2415, Acc: 0.5616\n",
      "Epoch [22/100] - Train Loss: 1.1653, Acc: 0.5832 | Val Loss: 1.1933, Acc: 0.5764\n",
      "Epoch [23/100] - Train Loss: 1.1494, Acc: 0.5934 | Val Loss: 1.1102, Acc: 0.6032\n",
      "Epoch [24/100] - Train Loss: 1.1234, Acc: 0.6017 | Val Loss: 1.1298, Acc: 0.5960\n",
      "Epoch [25/100] - Train Loss: 1.1034, Acc: 0.6096 | Val Loss: 1.1431, Acc: 0.5992\n",
      "Epoch [26/100] - Train Loss: 1.0810, Acc: 0.6195 | Val Loss: 1.1056, Acc: 0.6007\n",
      "Epoch [27/100] - Train Loss: 1.0609, Acc: 0.6240 | Val Loss: 1.0598, Acc: 0.6241\n",
      "Epoch [28/100] - Train Loss: 1.0402, Acc: 0.6304 | Val Loss: 1.0586, Acc: 0.6259\n",
      "Epoch [29/100] - Train Loss: 1.0213, Acc: 0.6382 | Val Loss: 1.0539, Acc: 0.6244\n",
      "Epoch [30/100] - Train Loss: 1.0014, Acc: 0.6473 | Val Loss: 1.0318, Acc: 0.6309\n",
      "Epoch [31/100] - Train Loss: 0.9807, Acc: 0.6532 | Val Loss: 1.0120, Acc: 0.6430\n",
      "Epoch [32/100] - Train Loss: 0.9647, Acc: 0.6574 | Val Loss: 0.9775, Acc: 0.6572\n",
      "Epoch [33/100] - Train Loss: 0.9434, Acc: 0.6638 | Val Loss: 0.9922, Acc: 0.6495\n",
      "Epoch [34/100] - Train Loss: 0.9216, Acc: 0.6718 | Val Loss: 1.0043, Acc: 0.6430\n",
      "Epoch [35/100] - Train Loss: 0.9081, Acc: 0.6773 | Val Loss: 1.0217, Acc: 0.6348\n",
      "Epoch [36/100] - Train Loss: 0.8918, Acc: 0.6853 | Val Loss: 0.9557, Acc: 0.6615\n",
      "Epoch [37/100] - Train Loss: 0.8686, Acc: 0.6903 | Val Loss: 0.9926, Acc: 0.6522\n",
      "Epoch [38/100] - Train Loss: 0.8560, Acc: 0.6980 | Val Loss: 0.9520, Acc: 0.6688\n",
      "Epoch [39/100] - Train Loss: 0.8393, Acc: 0.7041 | Val Loss: 1.0016, Acc: 0.6492\n",
      "Epoch [40/100] - Train Loss: 0.8202, Acc: 0.7116 | Val Loss: 0.9136, Acc: 0.6789\n",
      "Epoch [41/100] - Train Loss: 0.7997, Acc: 0.7170 | Val Loss: 0.9185, Acc: 0.6769\n",
      "Epoch [42/100] - Train Loss: 0.7845, Acc: 0.7248 | Val Loss: 0.9385, Acc: 0.6720\n",
      "Epoch [43/100] - Train Loss: 0.7689, Acc: 0.7282 | Val Loss: 0.9211, Acc: 0.6789\n",
      "Epoch [44/100] - Train Loss: 0.7507, Acc: 0.7316 | Val Loss: 0.9189, Acc: 0.6797\n",
      "Epoch [45/100] - Train Loss: 0.7369, Acc: 0.7394 | Val Loss: 0.9344, Acc: 0.6746\n",
      "Epoch [46/100] - Train Loss: 0.7181, Acc: 0.7476 | Val Loss: 0.8767, Acc: 0.6935\n",
      "Epoch [47/100] - Train Loss: 0.7078, Acc: 0.7500 | Val Loss: 0.8940, Acc: 0.6875\n",
      "Epoch [48/100] - Train Loss: 0.6906, Acc: 0.7558 | Val Loss: 0.9163, Acc: 0.6853\n",
      "Epoch [49/100] - Train Loss: 0.6721, Acc: 0.7623 | Val Loss: 0.8912, Acc: 0.6919\n",
      "Epoch [50/100] - Train Loss: 0.6587, Acc: 0.7660 | Val Loss: 0.9274, Acc: 0.6795\n",
      "Epoch [51/100] - Train Loss: 0.6423, Acc: 0.7713 | Val Loss: 0.8836, Acc: 0.6981\n",
      "Epoch [52/100] - Train Loss: 0.6265, Acc: 0.7780 | Val Loss: 0.9590, Acc: 0.6755\n",
      "Epoch [53/100] - Train Loss: 0.6116, Acc: 0.7843 | Val Loss: 0.8693, Acc: 0.7019\n",
      "Epoch [54/100] - Train Loss: 0.5949, Acc: 0.7881 | Val Loss: 0.9044, Acc: 0.6955\n",
      "Epoch [55/100] - Train Loss: 0.5799, Acc: 0.7922 | Val Loss: 0.8970, Acc: 0.7006\n",
      "Epoch [56/100] - Train Loss: 0.5650, Acc: 0.8002 | Val Loss: 0.8945, Acc: 0.7045\n",
      "Epoch [57/100] - Train Loss: 0.5511, Acc: 0.8006 | Val Loss: 0.8756, Acc: 0.7058\n",
      "Epoch [58/100] - Train Loss: 0.5357, Acc: 0.8091 | Val Loss: 0.8818, Acc: 0.7083\n",
      "Epoch [59/100] - Train Loss: 0.5232, Acc: 0.8162 | Val Loss: 0.9057, Acc: 0.7043\n",
      "Epoch [60/100] - Train Loss: 0.5043, Acc: 0.8179 | Val Loss: 0.9173, Acc: 0.7061\n",
      "Epoch [61/100] - Train Loss: 0.4944, Acc: 0.8257 | Val Loss: 0.9068, Acc: 0.7057\n",
      "Epoch [62/100] - Train Loss: 0.4774, Acc: 0.8299 | Val Loss: 0.8995, Acc: 0.7090\n",
      "Epoch [63/100] - Train Loss: 0.4646, Acc: 0.8335 | Val Loss: 0.9334, Acc: 0.7040\n",
      "Epoch [64/100] - Train Loss: 0.4534, Acc: 0.8379 | Val Loss: 1.0398, Acc: 0.6813\n",
      "Epoch [65/100] - Train Loss: 0.4404, Acc: 0.8422 | Val Loss: 0.9175, Acc: 0.7111\n",
      "Epoch [66/100] - Train Loss: 0.4236, Acc: 0.8480 | Val Loss: 0.9167, Acc: 0.7091\n",
      "Epoch [67/100] - Train Loss: 0.4120, Acc: 0.8522 | Val Loss: 0.9811, Acc: 0.7021\n",
      "Epoch [68/100] - Train Loss: 0.3948, Acc: 0.8569 | Val Loss: 0.9837, Acc: 0.7050\n",
      "Epoch [69/100] - Train Loss: 0.3851, Acc: 0.8633 | Val Loss: 0.9738, Acc: 0.7030\n",
      "Epoch [70/100] - Train Loss: 0.3792, Acc: 0.8629 | Val Loss: 0.9726, Acc: 0.7064\n",
      "Epoch [71/100] - Train Loss: 0.3628, Acc: 0.8713 | Val Loss: 0.9359, Acc: 0.7144\n",
      "Epoch [72/100] - Train Loss: 0.3478, Acc: 0.8775 | Val Loss: 0.9573, Acc: 0.7151\n",
      "Epoch [73/100] - Train Loss: 0.3391, Acc: 0.8786 | Val Loss: 1.0323, Acc: 0.6947\n",
      "Epoch [74/100] - Train Loss: 0.3281, Acc: 0.8827 | Val Loss: 1.0168, Acc: 0.7085\n",
      "Epoch [75/100] - Train Loss: 0.3197, Acc: 0.8860 | Val Loss: 0.9880, Acc: 0.7086\n",
      "Epoch [76/100] - Train Loss: 0.3078, Acc: 0.8884 | Val Loss: 0.9936, Acc: 0.7098\n",
      "Epoch [77/100] - Train Loss: 0.2986, Acc: 0.8942 | Val Loss: 1.0662, Acc: 0.7050\n",
      "Epoch [78/100] - Train Loss: 0.2889, Acc: 0.8969 | Val Loss: 1.0314, Acc: 0.7084\n",
      "Epoch [79/100] - Train Loss: 0.2864, Acc: 0.9001 | Val Loss: 1.0018, Acc: 0.7148\n",
      "Epoch [80/100] - Train Loss: 0.2671, Acc: 0.9039 | Val Loss: 1.0830, Acc: 0.7015\n",
      "Epoch [81/100] - Train Loss: 0.2601, Acc: 0.9058 | Val Loss: 1.0573, Acc: 0.7119\n",
      "Epoch [82/100] - Train Loss: 0.2463, Acc: 0.9117 | Val Loss: 1.1270, Acc: 0.7086\n",
      "Epoch [83/100] - Train Loss: 0.2452, Acc: 0.9127 | Val Loss: 1.0861, Acc: 0.7117\n",
      "Epoch [84/100] - Train Loss: 0.2360, Acc: 0.9171 | Val Loss: 1.0991, Acc: 0.7071\n",
      "Epoch [85/100] - Train Loss: 0.2253, Acc: 0.9192 | Val Loss: 1.1423, Acc: 0.7055\n",
      "Epoch [86/100] - Train Loss: 0.2222, Acc: 0.9194 | Val Loss: 1.1243, Acc: 0.7065\n",
      "Epoch [87/100] - Train Loss: 0.2187, Acc: 0.9213 | Val Loss: 1.0694, Acc: 0.7164\n",
      "Epoch [88/100] - Train Loss: 0.2122, Acc: 0.9249 | Val Loss: 1.1158, Acc: 0.7196\n",
      "Epoch [89/100] - Train Loss: 0.2005, Acc: 0.9279 | Val Loss: 1.1542, Acc: 0.7053\n",
      "Epoch [90/100] - Train Loss: 0.1990, Acc: 0.9296 | Val Loss: 1.1605, Acc: 0.7074\n",
      "Epoch [91/100] - Train Loss: 0.1917, Acc: 0.9307 | Val Loss: 1.1511, Acc: 0.7080\n",
      "Epoch [92/100] - Train Loss: 0.1829, Acc: 0.9368 | Val Loss: 1.2442, Acc: 0.7007\n",
      "Epoch [93/100] - Train Loss: 0.1752, Acc: 0.9406 | Val Loss: 1.1661, Acc: 0.7141\n",
      "Epoch [94/100] - Train Loss: 0.1746, Acc: 0.9376 | Val Loss: 1.1932, Acc: 0.7085\n",
      "Epoch [95/100] - Train Loss: 0.1681, Acc: 0.9404 | Val Loss: 1.2323, Acc: 0.7088\n",
      "Epoch [96/100] - Train Loss: 0.1587, Acc: 0.9450 | Val Loss: 1.2528, Acc: 0.7092\n",
      "Epoch [97/100] - Train Loss: 0.1610, Acc: 0.9419 | Val Loss: 1.2550, Acc: 0.7088\n",
      "Epoch [98/100] - Train Loss: 0.1605, Acc: 0.9432 | Val Loss: 1.2114, Acc: 0.7060\n",
      "Epoch [99/100] - Train Loss: 0.1503, Acc: 0.9472 | Val Loss: 1.2245, Acc: 0.7129\n",
      "Epoch [100/100] - Train Loss: 0.1431, Acc: 0.9494 | Val Loss: 1.2333, Acc: 0.7152\n",
      "TESTING COMPLETE!!\n",
      "Test Loss: 1.2275, Test Acc: 0.7188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       plane       0.76      0.74      0.75      1000\n",
      "         car       0.84      0.84      0.84      1000\n",
      "        bird       0.63      0.61      0.62      1000\n",
      "         cat       0.52      0.54      0.53      1000\n",
      "        deer       0.66      0.65      0.65      1000\n",
      "         dog       0.60      0.66      0.63      1000\n",
      "        frog       0.79      0.78      0.78      1000\n",
      "       horse       0.81      0.73      0.77      1000\n",
      "        ship       0.82      0.85      0.84      1000\n",
      "       truck       0.79      0.80      0.79      1000\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.72      0.72      0.72     10000\n",
      "weighted avg       0.72      0.72      0.72     10000\n",
      "\n",
      "DR:  0.4\n",
      "seed: 3\n",
      "Epoch [1/100] - Train Loss: 2.2989, Acc: 0.1114 | Val Loss: 2.2932, Acc: 0.1185\n",
      "Epoch [2/100] - Train Loss: 2.2747, Acc: 0.1660 | Val Loss: 2.2303, Acc: 0.2256\n",
      "Epoch [3/100] - Train Loss: 2.1251, Acc: 0.2328 | Val Loss: 1.9953, Acc: 0.2963\n",
      "Epoch [4/100] - Train Loss: 1.9495, Acc: 0.2980 | Val Loss: 1.8511, Acc: 0.3339\n",
      "Epoch [5/100] - Train Loss: 1.8363, Acc: 0.3377 | Val Loss: 1.7644, Acc: 0.3694\n",
      "Epoch [6/100] - Train Loss: 1.7411, Acc: 0.3679 | Val Loss: 1.6557, Acc: 0.3915\n",
      "Epoch [7/100] - Train Loss: 1.6705, Acc: 0.3912 | Val Loss: 1.5820, Acc: 0.4271\n",
      "Epoch [8/100] - Train Loss: 1.6158, Acc: 0.4138 | Val Loss: 1.5783, Acc: 0.4338\n",
      "Epoch [9/100] - Train Loss: 1.5690, Acc: 0.4289 | Val Loss: 1.5181, Acc: 0.4476\n",
      "Epoch [10/100] - Train Loss: 1.5282, Acc: 0.4467 | Val Loss: 1.5061, Acc: 0.4558\n",
      "Epoch [11/100] - Train Loss: 1.4870, Acc: 0.4600 | Val Loss: 1.4502, Acc: 0.4808\n",
      "Epoch [12/100] - Train Loss: 1.4530, Acc: 0.4782 | Val Loss: 1.3935, Acc: 0.4851\n",
      "Epoch [13/100] - Train Loss: 1.4240, Acc: 0.4851 | Val Loss: 1.3630, Acc: 0.5038\n",
      "Epoch [14/100] - Train Loss: 1.3906, Acc: 0.4979 | Val Loss: 1.3372, Acc: 0.5133\n",
      "Epoch [15/100] - Train Loss: 1.3649, Acc: 0.5076 | Val Loss: 1.3311, Acc: 0.5114\n",
      "Epoch [16/100] - Train Loss: 1.3360, Acc: 0.5224 | Val Loss: 1.2794, Acc: 0.5400\n",
      "Epoch [17/100] - Train Loss: 1.3028, Acc: 0.5341 | Val Loss: 1.2538, Acc: 0.5462\n",
      "Epoch [18/100] - Train Loss: 1.2801, Acc: 0.5384 | Val Loss: 1.2312, Acc: 0.5544\n",
      "Epoch [19/100] - Train Loss: 1.2536, Acc: 0.5520 | Val Loss: 1.2153, Acc: 0.5672\n",
      "Epoch [20/100] - Train Loss: 1.2320, Acc: 0.5567 | Val Loss: 1.2000, Acc: 0.5688\n",
      "Epoch [21/100] - Train Loss: 1.2024, Acc: 0.5682 | Val Loss: 1.1758, Acc: 0.5801\n",
      "Epoch [22/100] - Train Loss: 1.1786, Acc: 0.5748 | Val Loss: 1.1671, Acc: 0.5755\n",
      "Epoch [23/100] - Train Loss: 1.1530, Acc: 0.5881 | Val Loss: 1.2188, Acc: 0.5671\n",
      "Epoch [24/100] - Train Loss: 1.1281, Acc: 0.5961 | Val Loss: 1.1261, Acc: 0.5965\n",
      "Epoch [25/100] - Train Loss: 1.1060, Acc: 0.6065 | Val Loss: 1.0920, Acc: 0.6090\n",
      "Epoch [26/100] - Train Loss: 1.0831, Acc: 0.6136 | Val Loss: 1.0834, Acc: 0.6137\n",
      "Epoch [27/100] - Train Loss: 1.0629, Acc: 0.6231 | Val Loss: 1.0822, Acc: 0.6113\n",
      "Epoch [28/100] - Train Loss: 1.0376, Acc: 0.6288 | Val Loss: 1.0471, Acc: 0.6246\n",
      "Epoch [29/100] - Train Loss: 1.0169, Acc: 0.6363 | Val Loss: 1.0885, Acc: 0.6102\n",
      "Epoch [30/100] - Train Loss: 1.0015, Acc: 0.6422 | Val Loss: 1.0504, Acc: 0.6244\n",
      "Epoch [31/100] - Train Loss: 0.9796, Acc: 0.6531 | Val Loss: 1.0148, Acc: 0.6399\n",
      "Epoch [32/100] - Train Loss: 0.9598, Acc: 0.6597 | Val Loss: 1.0283, Acc: 0.6360\n",
      "Epoch [33/100] - Train Loss: 0.9356, Acc: 0.6701 | Val Loss: 0.9682, Acc: 0.6577\n",
      "Epoch [34/100] - Train Loss: 0.9207, Acc: 0.6741 | Val Loss: 0.9841, Acc: 0.6508\n",
      "Epoch [35/100] - Train Loss: 0.8979, Acc: 0.6818 | Val Loss: 0.9732, Acc: 0.6578\n",
      "Epoch [36/100] - Train Loss: 0.8828, Acc: 0.6863 | Val Loss: 0.9644, Acc: 0.6603\n",
      "Epoch [37/100] - Train Loss: 0.8645, Acc: 0.6937 | Val Loss: 0.9358, Acc: 0.6720\n",
      "Epoch [38/100] - Train Loss: 0.8492, Acc: 0.7013 | Val Loss: 0.9556, Acc: 0.6635\n",
      "Epoch [39/100] - Train Loss: 0.8286, Acc: 0.7078 | Val Loss: 0.9228, Acc: 0.6746\n",
      "Epoch [40/100] - Train Loss: 0.8073, Acc: 0.7177 | Val Loss: 0.9227, Acc: 0.6727\n",
      "Epoch [41/100] - Train Loss: 0.7971, Acc: 0.7195 | Val Loss: 0.9020, Acc: 0.6846\n",
      "Epoch [42/100] - Train Loss: 0.7732, Acc: 0.7266 | Val Loss: 0.9177, Acc: 0.6788\n",
      "Epoch [43/100] - Train Loss: 0.7575, Acc: 0.7332 | Val Loss: 0.8876, Acc: 0.6879\n",
      "Epoch [44/100] - Train Loss: 0.7393, Acc: 0.7405 | Val Loss: 0.9006, Acc: 0.6850\n",
      "Epoch [45/100] - Train Loss: 0.7242, Acc: 0.7440 | Val Loss: 0.8696, Acc: 0.6943\n",
      "Epoch [46/100] - Train Loss: 0.7088, Acc: 0.7453 | Val Loss: 0.8839, Acc: 0.6934\n",
      "Epoch [47/100] - Train Loss: 0.6927, Acc: 0.7553 | Val Loss: 0.9013, Acc: 0.6876\n",
      "Epoch [48/100] - Train Loss: 0.6727, Acc: 0.7621 | Val Loss: 0.8824, Acc: 0.6980\n",
      "Epoch [49/100] - Train Loss: 0.6609, Acc: 0.7642 | Val Loss: 0.8910, Acc: 0.6959\n",
      "Epoch [50/100] - Train Loss: 0.6505, Acc: 0.7704 | Val Loss: 0.8541, Acc: 0.7018\n",
      "Epoch [51/100] - Train Loss: 0.6292, Acc: 0.7748 | Val Loss: 0.8784, Acc: 0.6991\n",
      "Epoch [52/100] - Train Loss: 0.6075, Acc: 0.7842 | Val Loss: 0.8560, Acc: 0.7066\n",
      "Epoch [53/100] - Train Loss: 0.5950, Acc: 0.7883 | Val Loss: 0.9043, Acc: 0.6928\n",
      "Epoch [54/100] - Train Loss: 0.5795, Acc: 0.7938 | Val Loss: 0.8838, Acc: 0.7027\n",
      "Epoch [55/100] - Train Loss: 0.5663, Acc: 0.7956 | Val Loss: 0.9063, Acc: 0.7033\n",
      "Epoch [56/100] - Train Loss: 0.5514, Acc: 0.8012 | Val Loss: 0.8881, Acc: 0.7062\n",
      "Epoch [57/100] - Train Loss: 0.5307, Acc: 0.8111 | Val Loss: 0.8968, Acc: 0.7045\n",
      "Epoch [58/100] - Train Loss: 0.5190, Acc: 0.8130 | Val Loss: 0.8941, Acc: 0.7053\n",
      "Epoch [59/100] - Train Loss: 0.5093, Acc: 0.8185 | Val Loss: 0.9689, Acc: 0.6885\n",
      "Epoch [60/100] - Train Loss: 0.4935, Acc: 0.8222 | Val Loss: 0.8927, Acc: 0.7052\n",
      "Epoch [61/100] - Train Loss: 0.4789, Acc: 0.8288 | Val Loss: 0.8614, Acc: 0.7156\n",
      "Epoch [62/100] - Train Loss: 0.4593, Acc: 0.8348 | Val Loss: 0.9139, Acc: 0.7066\n",
      "Epoch [63/100] - Train Loss: 0.4493, Acc: 0.8385 | Val Loss: 0.9164, Acc: 0.7068\n",
      "Epoch [64/100] - Train Loss: 0.4360, Acc: 0.8455 | Val Loss: 0.9339, Acc: 0.7025\n",
      "Epoch [65/100] - Train Loss: 0.4233, Acc: 0.8470 | Val Loss: 0.8858, Acc: 0.7117\n",
      "Epoch [66/100] - Train Loss: 0.4044, Acc: 0.8565 | Val Loss: 0.9375, Acc: 0.7026\n",
      "Epoch [67/100] - Train Loss: 0.3909, Acc: 0.8609 | Val Loss: 0.9518, Acc: 0.7129\n",
      "Epoch [68/100] - Train Loss: 0.3887, Acc: 0.8621 | Val Loss: 0.9565, Acc: 0.7034\n",
      "Epoch [69/100] - Train Loss: 0.3792, Acc: 0.8633 | Val Loss: 0.9741, Acc: 0.7023\n",
      "Epoch [70/100] - Train Loss: 0.3603, Acc: 0.8714 | Val Loss: 0.9610, Acc: 0.7120\n",
      "Epoch [71/100] - Train Loss: 0.3474, Acc: 0.8749 | Val Loss: 0.9146, Acc: 0.7190\n",
      "Epoch [72/100] - Train Loss: 0.3330, Acc: 0.8811 | Val Loss: 0.9629, Acc: 0.7110\n",
      "Epoch [73/100] - Train Loss: 0.3264, Acc: 0.8826 | Val Loss: 0.9465, Acc: 0.7156\n",
      "Epoch [74/100] - Train Loss: 0.3115, Acc: 0.8880 | Val Loss: 0.9638, Acc: 0.7168\n",
      "Epoch [75/100] - Train Loss: 0.3143, Acc: 0.8880 | Val Loss: 1.0033, Acc: 0.7130\n",
      "Epoch [76/100] - Train Loss: 0.2909, Acc: 0.8946 | Val Loss: 0.9840, Acc: 0.7147\n",
      "Epoch [77/100] - Train Loss: 0.2865, Acc: 0.8989 | Val Loss: 1.0164, Acc: 0.7086\n",
      "Epoch [78/100] - Train Loss: 0.2734, Acc: 0.9037 | Val Loss: 1.0730, Acc: 0.7059\n",
      "Epoch [79/100] - Train Loss: 0.2625, Acc: 0.9049 | Val Loss: 1.0080, Acc: 0.7129\n",
      "Epoch [80/100] - Train Loss: 0.2530, Acc: 0.9097 | Val Loss: 1.0759, Acc: 0.7119\n",
      "Epoch [81/100] - Train Loss: 0.2531, Acc: 0.9097 | Val Loss: 1.0433, Acc: 0.7090\n",
      "Epoch [82/100] - Train Loss: 0.2394, Acc: 0.9144 | Val Loss: 1.0921, Acc: 0.7111\n",
      "Epoch [83/100] - Train Loss: 0.2360, Acc: 0.9155 | Val Loss: 1.1603, Acc: 0.7036\n",
      "Epoch [84/100] - Train Loss: 0.2294, Acc: 0.9174 | Val Loss: 1.0781, Acc: 0.7164\n",
      "Epoch [85/100] - Train Loss: 0.2215, Acc: 0.9227 | Val Loss: 1.0902, Acc: 0.7156\n",
      "Epoch [86/100] - Train Loss: 0.2106, Acc: 0.9251 | Val Loss: 1.1703, Acc: 0.7036\n",
      "Epoch [87/100] - Train Loss: 0.2028, Acc: 0.9275 | Val Loss: 1.1647, Acc: 0.7063\n",
      "Epoch [88/100] - Train Loss: 0.2008, Acc: 0.9277 | Val Loss: 1.1099, Acc: 0.7151\n",
      "Epoch [89/100] - Train Loss: 0.1978, Acc: 0.9293 | Val Loss: 1.1122, Acc: 0.7234\n",
      "Epoch [90/100] - Train Loss: 0.1836, Acc: 0.9359 | Val Loss: 1.1423, Acc: 0.7184\n",
      "Epoch [91/100] - Train Loss: 0.1785, Acc: 0.9353 | Val Loss: 1.1496, Acc: 0.7136\n",
      "Epoch [92/100] - Train Loss: 0.1769, Acc: 0.9378 | Val Loss: 1.1618, Acc: 0.7183\n",
      "Epoch [93/100] - Train Loss: 0.1721, Acc: 0.9411 | Val Loss: 1.1865, Acc: 0.7183\n",
      "Epoch [94/100] - Train Loss: 0.1674, Acc: 0.9411 | Val Loss: 1.2075, Acc: 0.7153\n",
      "Epoch [95/100] - Train Loss: 0.1608, Acc: 0.9445 | Val Loss: 1.2190, Acc: 0.7144\n",
      "Epoch [96/100] - Train Loss: 0.1632, Acc: 0.9413 | Val Loss: 1.2264, Acc: 0.7181\n",
      "Epoch [97/100] - Train Loss: 0.1454, Acc: 0.9486 | Val Loss: 1.2616, Acc: 0.7172\n",
      "Epoch [98/100] - Train Loss: 0.1490, Acc: 0.9474 | Val Loss: 1.2579, Acc: 0.7171\n",
      "Epoch [99/100] - Train Loss: 0.1486, Acc: 0.9479 | Val Loss: 1.2156, Acc: 0.7170\n",
      "Epoch [100/100] - Train Loss: 0.1425, Acc: 0.9495 | Val Loss: 1.3162, Acc: 0.7089\n",
      "TESTING COMPLETE!!\n",
      "Test Loss: 1.3317, Test Acc: 0.7077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       plane       0.67      0.82      0.73      1000\n",
      "         car       0.82      0.83      0.82      1000\n",
      "        bird       0.55      0.69      0.61      1000\n",
      "         cat       0.54      0.50      0.52      1000\n",
      "        deer       0.72      0.62      0.67      1000\n",
      "         dog       0.59      0.65      0.62      1000\n",
      "        frog       0.87      0.68      0.77      1000\n",
      "       horse       0.77      0.78      0.77      1000\n",
      "        ship       0.85      0.79      0.82      1000\n",
      "       truck       0.79      0.73      0.76      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.71      0.71     10000\n",
      "weighted avg       0.72      0.71      0.71     10000\n",
      "\n",
      "DR:  0.4\n",
      "seed: 4\n",
      "Epoch [1/100] - Train Loss: 2.2951, Acc: 0.1162 | Val Loss: 2.2786, Acc: 0.1854\n",
      "Epoch [2/100] - Train Loss: 2.2106, Acc: 0.2065 | Val Loss: 2.1056, Acc: 0.2520\n",
      "Epoch [3/100] - Train Loss: 2.0484, Acc: 0.2544 | Val Loss: 1.9691, Acc: 0.2891\n",
      "Epoch [4/100] - Train Loss: 1.9583, Acc: 0.2870 | Val Loss: 1.8903, Acc: 0.3147\n",
      "Epoch [5/100] - Train Loss: 1.8718, Acc: 0.3195 | Val Loss: 1.7886, Acc: 0.3529\n",
      "Epoch [6/100] - Train Loss: 1.7689, Acc: 0.3574 | Val Loss: 1.6668, Acc: 0.3927\n",
      "Epoch [7/100] - Train Loss: 1.6785, Acc: 0.3919 | Val Loss: 1.6075, Acc: 0.4236\n",
      "Epoch [8/100] - Train Loss: 1.6080, Acc: 0.4150 | Val Loss: 1.5261, Acc: 0.4329\n",
      "Epoch [9/100] - Train Loss: 1.5526, Acc: 0.4388 | Val Loss: 1.4839, Acc: 0.4558\n",
      "Epoch [10/100] - Train Loss: 1.5096, Acc: 0.4540 | Val Loss: 1.4325, Acc: 0.4817\n",
      "Epoch [11/100] - Train Loss: 1.4662, Acc: 0.4708 | Val Loss: 1.3890, Acc: 0.4988\n",
      "Epoch [12/100] - Train Loss: 1.4270, Acc: 0.4871 | Val Loss: 1.4087, Acc: 0.4906\n",
      "Epoch [13/100] - Train Loss: 1.3981, Acc: 0.4971 | Val Loss: 1.3428, Acc: 0.5154\n",
      "Epoch [14/100] - Train Loss: 1.3698, Acc: 0.5046 | Val Loss: 1.3137, Acc: 0.5266\n",
      "Epoch [15/100] - Train Loss: 1.3433, Acc: 0.5179 | Val Loss: 1.2843, Acc: 0.5322\n",
      "Epoch [16/100] - Train Loss: 1.3250, Acc: 0.5227 | Val Loss: 1.2759, Acc: 0.5441\n",
      "Epoch [17/100] - Train Loss: 1.2934, Acc: 0.5347 | Val Loss: 1.2663, Acc: 0.5454\n",
      "Epoch [18/100] - Train Loss: 1.2666, Acc: 0.5489 | Val Loss: 1.2174, Acc: 0.5666\n",
      "Epoch [19/100] - Train Loss: 1.2409, Acc: 0.5545 | Val Loss: 1.2122, Acc: 0.5710\n",
      "Epoch [20/100] - Train Loss: 1.2242, Acc: 0.5646 | Val Loss: 1.2049, Acc: 0.5674\n",
      "Epoch [21/100] - Train Loss: 1.1987, Acc: 0.5746 | Val Loss: 1.1511, Acc: 0.5912\n",
      "Epoch [22/100] - Train Loss: 1.1750, Acc: 0.5826 | Val Loss: 1.1612, Acc: 0.5839\n",
      "Epoch [23/100] - Train Loss: 1.1526, Acc: 0.5895 | Val Loss: 1.1761, Acc: 0.5822\n",
      "Epoch [24/100] - Train Loss: 1.1317, Acc: 0.6002 | Val Loss: 1.1111, Acc: 0.6047\n",
      "Epoch [25/100] - Train Loss: 1.1031, Acc: 0.6108 | Val Loss: 1.1376, Acc: 0.5923\n",
      "Epoch [26/100] - Train Loss: 1.0808, Acc: 0.6143 | Val Loss: 1.0694, Acc: 0.6207\n",
      "Epoch [27/100] - Train Loss: 1.0656, Acc: 0.6241 | Val Loss: 1.1057, Acc: 0.6052\n",
      "Epoch [28/100] - Train Loss: 1.0406, Acc: 0.6305 | Val Loss: 1.0476, Acc: 0.6268\n",
      "Epoch [29/100] - Train Loss: 1.0237, Acc: 0.6384 | Val Loss: 1.0400, Acc: 0.6309\n",
      "Epoch [30/100] - Train Loss: 1.0008, Acc: 0.6447 | Val Loss: 1.1093, Acc: 0.6056\n",
      "Epoch [31/100] - Train Loss: 0.9764, Acc: 0.6556 | Val Loss: 1.0399, Acc: 0.6283\n",
      "Epoch [32/100] - Train Loss: 0.9634, Acc: 0.6582 | Val Loss: 1.0076, Acc: 0.6417\n",
      "Epoch [33/100] - Train Loss: 0.9354, Acc: 0.6683 | Val Loss: 1.0060, Acc: 0.6409\n",
      "Epoch [34/100] - Train Loss: 0.9162, Acc: 0.6765 | Val Loss: 0.9772, Acc: 0.6521\n",
      "Epoch [35/100] - Train Loss: 0.9012, Acc: 0.6793 | Val Loss: 0.9748, Acc: 0.6548\n",
      "Epoch [36/100] - Train Loss: 0.8843, Acc: 0.6868 | Val Loss: 0.9649, Acc: 0.6604\n",
      "Epoch [37/100] - Train Loss: 0.8644, Acc: 0.6954 | Val Loss: 0.9327, Acc: 0.6717\n",
      "Epoch [38/100] - Train Loss: 0.8430, Acc: 0.7016 | Val Loss: 0.9739, Acc: 0.6567\n",
      "Epoch [39/100] - Train Loss: 0.8269, Acc: 0.7058 | Val Loss: 0.9544, Acc: 0.6619\n",
      "Epoch [40/100] - Train Loss: 0.8065, Acc: 0.7143 | Val Loss: 0.9419, Acc: 0.6659\n",
      "Epoch [41/100] - Train Loss: 0.8021, Acc: 0.7150 | Val Loss: 0.9248, Acc: 0.6754\n",
      "Epoch [42/100] - Train Loss: 0.7813, Acc: 0.7240 | Val Loss: 0.9462, Acc: 0.6694\n",
      "Epoch [43/100] - Train Loss: 0.7580, Acc: 0.7328 | Val Loss: 0.9174, Acc: 0.6779\n",
      "Epoch [44/100] - Train Loss: 0.7383, Acc: 0.7390 | Val Loss: 0.8942, Acc: 0.6866\n",
      "Epoch [45/100] - Train Loss: 0.7273, Acc: 0.7415 | Val Loss: 0.9793, Acc: 0.6605\n",
      "Epoch [46/100] - Train Loss: 0.7131, Acc: 0.7472 | Val Loss: 0.9743, Acc: 0.6603\n",
      "Epoch [47/100] - Train Loss: 0.6965, Acc: 0.7523 | Val Loss: 0.8930, Acc: 0.6822\n",
      "Epoch [48/100] - Train Loss: 0.6772, Acc: 0.7600 | Val Loss: 0.8875, Acc: 0.6911\n",
      "Epoch [49/100] - Train Loss: 0.6636, Acc: 0.7666 | Val Loss: 0.8974, Acc: 0.6883\n",
      "Epoch [50/100] - Train Loss: 0.6448, Acc: 0.7701 | Val Loss: 0.9014, Acc: 0.6864\n",
      "Epoch [51/100] - Train Loss: 0.6302, Acc: 0.7769 | Val Loss: 0.9009, Acc: 0.6916\n",
      "Epoch [52/100] - Train Loss: 0.6088, Acc: 0.7809 | Val Loss: 0.8953, Acc: 0.6961\n",
      "Epoch [53/100] - Train Loss: 0.5916, Acc: 0.7896 | Val Loss: 0.8974, Acc: 0.6947\n",
      "Epoch [54/100] - Train Loss: 0.5810, Acc: 0.7920 | Val Loss: 0.9515, Acc: 0.6820\n",
      "Epoch [55/100] - Train Loss: 0.5687, Acc: 0.7993 | Val Loss: 0.9398, Acc: 0.6844\n",
      "Epoch [56/100] - Train Loss: 0.5545, Acc: 0.8030 | Val Loss: 0.8875, Acc: 0.6990\n",
      "Epoch [57/100] - Train Loss: 0.5317, Acc: 0.8108 | Val Loss: 0.8903, Acc: 0.7048\n",
      "Epoch [58/100] - Train Loss: 0.5181, Acc: 0.8136 | Val Loss: 0.9204, Acc: 0.6935\n",
      "Epoch [59/100] - Train Loss: 0.5053, Acc: 0.8191 | Val Loss: 0.9125, Acc: 0.6998\n",
      "Epoch [60/100] - Train Loss: 0.4891, Acc: 0.8245 | Val Loss: 0.9388, Acc: 0.6960\n",
      "Epoch [61/100] - Train Loss: 0.4786, Acc: 0.8300 | Val Loss: 0.9210, Acc: 0.6951\n",
      "Epoch [62/100] - Train Loss: 0.4594, Acc: 0.8345 | Val Loss: 0.9378, Acc: 0.6930\n",
      "Epoch [63/100] - Train Loss: 0.4444, Acc: 0.8417 | Val Loss: 0.9449, Acc: 0.6953\n",
      "Epoch [64/100] - Train Loss: 0.4342, Acc: 0.8438 | Val Loss: 0.9270, Acc: 0.6985\n",
      "Epoch [65/100] - Train Loss: 0.4229, Acc: 0.8495 | Val Loss: 0.9269, Acc: 0.7013\n",
      "Epoch [66/100] - Train Loss: 0.4045, Acc: 0.8549 | Val Loss: 0.9427, Acc: 0.7031\n",
      "Epoch [67/100] - Train Loss: 0.3970, Acc: 0.8603 | Val Loss: 0.9553, Acc: 0.7016\n",
      "Epoch [68/100] - Train Loss: 0.3754, Acc: 0.8640 | Val Loss: 0.9744, Acc: 0.7040\n",
      "Epoch [69/100] - Train Loss: 0.3747, Acc: 0.8654 | Val Loss: 0.9953, Acc: 0.6999\n",
      "Epoch [70/100] - Train Loss: 0.3588, Acc: 0.8707 | Val Loss: 0.9923, Acc: 0.7040\n",
      "Epoch [71/100] - Train Loss: 0.3477, Acc: 0.8752 | Val Loss: 1.1083, Acc: 0.6811\n",
      "Epoch [72/100] - Train Loss: 0.3318, Acc: 0.8799 | Val Loss: 1.0448, Acc: 0.6944\n",
      "Epoch [73/100] - Train Loss: 0.3227, Acc: 0.8850 | Val Loss: 1.0152, Acc: 0.7036\n",
      "Epoch [74/100] - Train Loss: 0.3089, Acc: 0.8895 | Val Loss: 1.0486, Acc: 0.6896\n",
      "Epoch [75/100] - Train Loss: 0.3036, Acc: 0.8930 | Val Loss: 1.0264, Acc: 0.7080\n",
      "Epoch [76/100] - Train Loss: 0.2913, Acc: 0.8965 | Val Loss: 1.0541, Acc: 0.6999\n",
      "Epoch [77/100] - Train Loss: 0.2881, Acc: 0.8991 | Val Loss: 1.0233, Acc: 0.7020\n",
      "Epoch [78/100] - Train Loss: 0.2769, Acc: 0.9013 | Val Loss: 1.0283, Acc: 0.7027\n",
      "Epoch [79/100] - Train Loss: 0.2661, Acc: 0.9052 | Val Loss: 1.0862, Acc: 0.7049\n",
      "Epoch [80/100] - Train Loss: 0.2566, Acc: 0.9074 | Val Loss: 1.1078, Acc: 0.6967\n",
      "Epoch [81/100] - Train Loss: 0.2504, Acc: 0.9098 | Val Loss: 1.0820, Acc: 0.7005\n",
      "Epoch [82/100] - Train Loss: 0.2414, Acc: 0.9146 | Val Loss: 1.1287, Acc: 0.7012\n",
      "Epoch [83/100] - Train Loss: 0.2297, Acc: 0.9190 | Val Loss: 1.0955, Acc: 0.7070\n",
      "Epoch [84/100] - Train Loss: 0.2205, Acc: 0.9216 | Val Loss: 1.1213, Acc: 0.6991\n",
      "Epoch [85/100] - Train Loss: 0.2171, Acc: 0.9230 | Val Loss: 1.1970, Acc: 0.6979\n",
      "Epoch [86/100] - Train Loss: 0.2146, Acc: 0.9231 | Val Loss: 1.1252, Acc: 0.7016\n",
      "Epoch [87/100] - Train Loss: 0.2032, Acc: 0.9284 | Val Loss: 1.1671, Acc: 0.7021\n",
      "Epoch [88/100] - Train Loss: 0.2037, Acc: 0.9277 | Val Loss: 1.1675, Acc: 0.7077\n",
      "Epoch [89/100] - Train Loss: 0.1924, Acc: 0.9326 | Val Loss: 1.2092, Acc: 0.7023\n",
      "Epoch [90/100] - Train Loss: 0.1853, Acc: 0.9341 | Val Loss: 1.2930, Acc: 0.6984\n",
      "Epoch [91/100] - Train Loss: 0.1792, Acc: 0.9374 | Val Loss: 1.2236, Acc: 0.7031\n",
      "Epoch [92/100] - Train Loss: 0.1707, Acc: 0.9392 | Val Loss: 1.2646, Acc: 0.6987\n",
      "Epoch [93/100] - Train Loss: 0.1706, Acc: 0.9412 | Val Loss: 1.2683, Acc: 0.6916\n",
      "Epoch [94/100] - Train Loss: 0.1675, Acc: 0.9415 | Val Loss: 1.2392, Acc: 0.7075\n",
      "Epoch [95/100] - Train Loss: 0.1627, Acc: 0.9418 | Val Loss: 1.2203, Acc: 0.7067\n",
      "Epoch [96/100] - Train Loss: 0.1561, Acc: 0.9442 | Val Loss: 1.2647, Acc: 0.7032\n",
      "Epoch [97/100] - Train Loss: 0.1488, Acc: 0.9487 | Val Loss: 1.3460, Acc: 0.6923\n",
      "Epoch [98/100] - Train Loss: 0.1495, Acc: 0.9479 | Val Loss: 1.3969, Acc: 0.6933\n",
      "Epoch [99/100] - Train Loss: 0.1443, Acc: 0.9488 | Val Loss: 1.3426, Acc: 0.7034\n",
      "Epoch [100/100] - Train Loss: 0.1417, Acc: 0.9503 | Val Loss: 1.3525, Acc: 0.7031\n",
      "TESTING COMPLETE!!\n",
      "Test Loss: 1.3410, Test Acc: 0.7103\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       plane       0.72      0.80      0.76      1000\n",
      "         car       0.84      0.82      0.83      1000\n",
      "        bird       0.67      0.58      0.62      1000\n",
      "         cat       0.51      0.52      0.51      1000\n",
      "        deer       0.72      0.57      0.64      1000\n",
      "         dog       0.54      0.68      0.61      1000\n",
      "        frog       0.80      0.76      0.78      1000\n",
      "       horse       0.74      0.75      0.74      1000\n",
      "        ship       0.83      0.83      0.83      1000\n",
      "       truck       0.79      0.79      0.79      1000\n",
      "\n",
      "    accuracy                           0.71     10000\n",
      "   macro avg       0.72      0.71      0.71     10000\n",
      "weighted avg       0.72      0.71      0.71     10000\n",
      "\n",
      "average for \n",
      "DR:  0.4\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DR:  0.6\n",
      "DR:  0.6\n",
      "seed: 0\n",
      "Epoch [1/100] - Train Loss: 2.2973, Acc: 0.1148 | Val Loss: 2.2869, Acc: 0.1719\n",
      "Epoch [2/100] - Train Loss: 2.2508, Acc: 0.1834 | Val Loss: 2.1645, Acc: 0.2259\n",
      "Epoch [3/100] - Train Loss: 2.1023, Acc: 0.2241 | Val Loss: 2.0007, Acc: 0.2831\n",
      "Epoch [4/100] - Train Loss: 1.9947, Acc: 0.2640 | Val Loss: 1.8919, Acc: 0.3268\n",
      "Epoch [5/100] - Train Loss: 1.8945, Acc: 0.3041 | Val Loss: 1.8095, Acc: 0.3526\n",
      "Epoch [6/100] - Train Loss: 1.8035, Acc: 0.3430 | Val Loss: 1.6864, Acc: 0.3917\n",
      "Epoch [7/100] - Train Loss: 1.7364, Acc: 0.3644 | Val Loss: 1.6244, Acc: 0.4129\n",
      "Epoch [8/100] - Train Loss: 1.6740, Acc: 0.3900 | Val Loss: 1.5736, Acc: 0.4338\n",
      "Epoch [9/100] - Train Loss: 1.6348, Acc: 0.4045 | Val Loss: 1.5300, Acc: 0.4352\n",
      "Epoch [10/100] - Train Loss: 1.5969, Acc: 0.4194 | Val Loss: 1.4838, Acc: 0.4541\n",
      "Epoch [11/100] - Train Loss: 1.5669, Acc: 0.4296 | Val Loss: 1.4749, Acc: 0.4663\n",
      "Epoch [12/100] - Train Loss: 1.5336, Acc: 0.4405 | Val Loss: 1.4294, Acc: 0.4778\n",
      "Epoch [13/100] - Train Loss: 1.5147, Acc: 0.4529 | Val Loss: 1.4082, Acc: 0.4889\n",
      "Epoch [14/100] - Train Loss: 1.4865, Acc: 0.4655 | Val Loss: 1.3925, Acc: 0.4929\n",
      "Epoch [15/100] - Train Loss: 1.4650, Acc: 0.4713 | Val Loss: 1.3689, Acc: 0.5018\n",
      "Epoch [16/100] - Train Loss: 1.4401, Acc: 0.4823 | Val Loss: 1.3518, Acc: 0.5082\n",
      "Epoch [17/100] - Train Loss: 1.4129, Acc: 0.4899 | Val Loss: 1.3688, Acc: 0.5059\n",
      "Epoch [18/100] - Train Loss: 1.3941, Acc: 0.5012 | Val Loss: 1.3437, Acc: 0.5143\n",
      "Epoch [19/100] - Train Loss: 1.3716, Acc: 0.5079 | Val Loss: 1.3053, Acc: 0.5211\n",
      "Epoch [20/100] - Train Loss: 1.3516, Acc: 0.5143 | Val Loss: 1.2960, Acc: 0.5229\n",
      "Epoch [21/100] - Train Loss: 1.3284, Acc: 0.5261 | Val Loss: 1.2693, Acc: 0.5383\n",
      "Epoch [22/100] - Train Loss: 1.3069, Acc: 0.5358 | Val Loss: 1.2079, Acc: 0.5693\n",
      "Epoch [23/100] - Train Loss: 1.2884, Acc: 0.5403 | Val Loss: 1.2010, Acc: 0.5655\n",
      "Epoch [24/100] - Train Loss: 1.2633, Acc: 0.5472 | Val Loss: 1.1742, Acc: 0.5767\n",
      "Epoch [25/100] - Train Loss: 1.2477, Acc: 0.5553 | Val Loss: 1.1942, Acc: 0.5731\n",
      "Epoch [26/100] - Train Loss: 1.2197, Acc: 0.5654 | Val Loss: 1.1519, Acc: 0.5861\n",
      "Epoch [27/100] - Train Loss: 1.2057, Acc: 0.5755 | Val Loss: 1.1223, Acc: 0.5996\n",
      "Epoch [28/100] - Train Loss: 1.1853, Acc: 0.5813 | Val Loss: 1.1194, Acc: 0.6020\n",
      "Epoch [29/100] - Train Loss: 1.1609, Acc: 0.5882 | Val Loss: 1.0896, Acc: 0.6090\n",
      "Epoch [30/100] - Train Loss: 1.1395, Acc: 0.5985 | Val Loss: 1.0703, Acc: 0.6190\n",
      "Epoch [31/100] - Train Loss: 1.1265, Acc: 0.6034 | Val Loss: 1.0573, Acc: 0.6233\n",
      "Epoch [32/100] - Train Loss: 1.1081, Acc: 0.6113 | Val Loss: 1.0607, Acc: 0.6251\n",
      "Epoch [33/100] - Train Loss: 1.0880, Acc: 0.6148 | Val Loss: 1.0674, Acc: 0.6130\n",
      "Epoch [34/100] - Train Loss: 1.0765, Acc: 0.6245 | Val Loss: 1.0512, Acc: 0.6265\n",
      "Epoch [35/100] - Train Loss: 1.0578, Acc: 0.6284 | Val Loss: 1.0373, Acc: 0.6342\n",
      "Epoch [36/100] - Train Loss: 1.0308, Acc: 0.6372 | Val Loss: 0.9835, Acc: 0.6507\n",
      "Epoch [37/100] - Train Loss: 1.0134, Acc: 0.6402 | Val Loss: 1.0036, Acc: 0.6463\n",
      "Epoch [38/100] - Train Loss: 0.9987, Acc: 0.6493 | Val Loss: 0.9983, Acc: 0.6442\n",
      "Epoch [39/100] - Train Loss: 0.9816, Acc: 0.6555 | Val Loss: 0.9659, Acc: 0.6564\n",
      "Epoch [40/100] - Train Loss: 0.9608, Acc: 0.6633 | Val Loss: 1.0076, Acc: 0.6487\n",
      "Epoch [41/100] - Train Loss: 0.9394, Acc: 0.6695 | Val Loss: 0.9495, Acc: 0.6640\n",
      "Epoch [42/100] - Train Loss: 0.9349, Acc: 0.6705 | Val Loss: 0.9586, Acc: 0.6648\n",
      "Epoch [43/100] - Train Loss: 0.9140, Acc: 0.6795 | Val Loss: 0.9129, Acc: 0.6764\n",
      "Epoch [44/100] - Train Loss: 0.8998, Acc: 0.6845 | Val Loss: 0.9381, Acc: 0.6677\n",
      "Epoch [45/100] - Train Loss: 0.8809, Acc: 0.6905 | Val Loss: 0.9271, Acc: 0.6703\n",
      "Epoch [46/100] - Train Loss: 0.8721, Acc: 0.6959 | Val Loss: 0.9135, Acc: 0.6792\n",
      "Epoch [47/100] - Train Loss: 0.8547, Acc: 0.6974 | Val Loss: 0.8857, Acc: 0.6860\n",
      "Epoch [48/100] - Train Loss: 0.8420, Acc: 0.7059 | Val Loss: 0.9319, Acc: 0.6714\n",
      "Epoch [49/100] - Train Loss: 0.8288, Acc: 0.7105 | Val Loss: 0.9016, Acc: 0.6820\n",
      "Epoch [50/100] - Train Loss: 0.8170, Acc: 0.7126 | Val Loss: 0.9317, Acc: 0.6741\n",
      "Epoch [51/100] - Train Loss: 0.7971, Acc: 0.7238 | Val Loss: 0.8702, Acc: 0.6905\n",
      "Epoch [52/100] - Train Loss: 0.7802, Acc: 0.7285 | Val Loss: 0.8695, Acc: 0.6965\n",
      "Epoch [53/100] - Train Loss: 0.7729, Acc: 0.7285 | Val Loss: 0.8849, Acc: 0.6889\n",
      "Epoch [54/100] - Train Loss: 0.7574, Acc: 0.7339 | Val Loss: 0.8658, Acc: 0.6963\n",
      "Epoch [55/100] - Train Loss: 0.7484, Acc: 0.7376 | Val Loss: 0.9094, Acc: 0.6820\n",
      "Epoch [56/100] - Train Loss: 0.7360, Acc: 0.7416 | Val Loss: 0.8529, Acc: 0.7032\n",
      "Epoch [57/100] - Train Loss: 0.7158, Acc: 0.7495 | Val Loss: 0.8605, Acc: 0.6993\n",
      "Epoch [58/100] - Train Loss: 0.7022, Acc: 0.7519 | Val Loss: 0.8747, Acc: 0.6981\n",
      "Epoch [59/100] - Train Loss: 0.6925, Acc: 0.7535 | Val Loss: 0.8600, Acc: 0.7016\n",
      "Epoch [60/100] - Train Loss: 0.6783, Acc: 0.7611 | Val Loss: 0.8648, Acc: 0.6995\n",
      "Epoch [61/100] - Train Loss: 0.6653, Acc: 0.7641 | Val Loss: 0.8553, Acc: 0.7053\n",
      "Epoch [62/100] - Train Loss: 0.6478, Acc: 0.7721 | Val Loss: 0.8741, Acc: 0.7013\n",
      "Epoch [63/100] - Train Loss: 0.6482, Acc: 0.7712 | Val Loss: 0.8612, Acc: 0.7047\n",
      "Epoch [64/100] - Train Loss: 0.6305, Acc: 0.7769 | Val Loss: 0.8929, Acc: 0.6969\n",
      "Epoch [65/100] - Train Loss: 0.6207, Acc: 0.7795 | Val Loss: 0.8752, Acc: 0.7055\n",
      "Epoch [66/100] - Train Loss: 0.6076, Acc: 0.7849 | Val Loss: 0.8785, Acc: 0.7056\n",
      "Epoch [67/100] - Train Loss: 0.5961, Acc: 0.7897 | Val Loss: 0.8504, Acc: 0.7076\n",
      "Epoch [68/100] - Train Loss: 0.5760, Acc: 0.7939 | Val Loss: 0.8633, Acc: 0.7088\n",
      "Epoch [69/100] - Train Loss: 0.5698, Acc: 0.7980 | Val Loss: 0.8858, Acc: 0.7070\n",
      "Epoch [70/100] - Train Loss: 0.5520, Acc: 0.8020 | Val Loss: 0.9061, Acc: 0.7005\n",
      "Epoch [71/100] - Train Loss: 0.5456, Acc: 0.8038 | Val Loss: 0.8464, Acc: 0.7189\n",
      "Epoch [72/100] - Train Loss: 0.5382, Acc: 0.8069 | Val Loss: 0.8530, Acc: 0.7198\n",
      "Epoch [73/100] - Train Loss: 0.5295, Acc: 0.8100 | Val Loss: 0.8593, Acc: 0.7128\n",
      "Epoch [74/100] - Train Loss: 0.5123, Acc: 0.8142 | Val Loss: 0.8515, Acc: 0.7181\n",
      "Epoch [75/100] - Train Loss: 0.5090, Acc: 0.8167 | Val Loss: 0.8589, Acc: 0.7182\n",
      "Epoch [76/100] - Train Loss: 0.4938, Acc: 0.8227 | Val Loss: 0.8831, Acc: 0.7124\n",
      "Epoch [77/100] - Train Loss: 0.4805, Acc: 0.8293 | Val Loss: 0.8807, Acc: 0.7142\n",
      "Epoch [78/100] - Train Loss: 0.4765, Acc: 0.8277 | Val Loss: 0.9071, Acc: 0.7105\n",
      "Epoch [79/100] - Train Loss: 0.4643, Acc: 0.8314 | Val Loss: 0.9129, Acc: 0.7116\n",
      "Epoch [80/100] - Train Loss: 0.4464, Acc: 0.8393 | Val Loss: 0.8853, Acc: 0.7175\n",
      "Epoch [81/100] - Train Loss: 0.4386, Acc: 0.8419 | Val Loss: 0.9050, Acc: 0.7141\n",
      "Epoch [82/100] - Train Loss: 0.4300, Acc: 0.8454 | Val Loss: 0.9081, Acc: 0.7162\n",
      "Epoch [83/100] - Train Loss: 0.4206, Acc: 0.8474 | Val Loss: 0.9336, Acc: 0.7137\n",
      "Epoch [84/100] - Train Loss: 0.4139, Acc: 0.8491 | Val Loss: 0.9144, Acc: 0.7207\n",
      "Epoch [85/100] - Train Loss: 0.4096, Acc: 0.8503 | Val Loss: 0.9149, Acc: 0.7158\n",
      "Epoch [86/100] - Train Loss: 0.3977, Acc: 0.8574 | Val Loss: 0.8880, Acc: 0.7192\n",
      "Epoch [87/100] - Train Loss: 0.3838, Acc: 0.8600 | Val Loss: 0.9418, Acc: 0.7168\n",
      "Epoch [88/100] - Train Loss: 0.3775, Acc: 0.8617 | Val Loss: 0.9783, Acc: 0.7122\n",
      "Epoch [89/100] - Train Loss: 0.3727, Acc: 0.8646 | Val Loss: 1.0282, Acc: 0.7018\n",
      "Epoch [90/100] - Train Loss: 0.3656, Acc: 0.8643 | Val Loss: 0.9982, Acc: 0.7087\n",
      "Epoch [91/100] - Train Loss: 0.3540, Acc: 0.8719 | Val Loss: 0.9719, Acc: 0.7194\n",
      "Epoch [92/100] - Train Loss: 0.3445, Acc: 0.8746 | Val Loss: 1.0074, Acc: 0.7159\n",
      "Epoch [93/100] - Train Loss: 0.3298, Acc: 0.8816 | Val Loss: 0.9492, Acc: 0.7209\n",
      "Epoch [94/100] - Train Loss: 0.3297, Acc: 0.8832 | Val Loss: 0.9999, Acc: 0.7211\n",
      "Epoch [95/100] - Train Loss: 0.3190, Acc: 0.8835 | Val Loss: 1.0041, Acc: 0.7148\n",
      "Epoch [96/100] - Train Loss: 0.3153, Acc: 0.8867 | Val Loss: 1.0525, Acc: 0.7045\n",
      "Epoch [97/100] - Train Loss: 0.3085, Acc: 0.8861 | Val Loss: 1.1216, Acc: 0.6981\n",
      "Epoch [98/100] - Train Loss: 0.3022, Acc: 0.8875 | Val Loss: 1.0414, Acc: 0.7161\n",
      "Epoch [99/100] - Train Loss: 0.2896, Acc: 0.8941 | Val Loss: 1.0050, Acc: 0.7207\n",
      "Epoch [100/100] - Train Loss: 0.2909, Acc: 0.8944 | Val Loss: 1.0487, Acc: 0.7130\n",
      "TESTING COMPLETE!!\n",
      "Test Loss: 1.0464, Test Acc: 0.7152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       plane       0.74      0.75      0.74      1000\n",
      "         car       0.81      0.85      0.83      1000\n",
      "        bird       0.54      0.69      0.61      1000\n",
      "         cat       0.56      0.51      0.53      1000\n",
      "        deer       0.65      0.67      0.66      1000\n",
      "         dog       0.66      0.61      0.64      1000\n",
      "        frog       0.74      0.82      0.78      1000\n",
      "       horse       0.83      0.69      0.75      1000\n",
      "        ship       0.80      0.86      0.83      1000\n",
      "       truck       0.88      0.71      0.79      1000\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.72      0.72      0.72     10000\n",
      "weighted avg       0.72      0.72      0.72     10000\n",
      "\n",
      "DR:  0.6\n",
      "seed: 1\n",
      "Epoch [1/100] - Train Loss: 2.2925, Acc: 0.1418 | Val Loss: 2.2720, Acc: 0.2247\n",
      "Epoch [2/100] - Train Loss: 2.2013, Acc: 0.2015 | Val Loss: 2.0911, Acc: 0.2622\n",
      "Epoch [3/100] - Train Loss: 2.0534, Acc: 0.2577 | Val Loss: 1.9341, Acc: 0.3061\n",
      "Epoch [4/100] - Train Loss: 1.9321, Acc: 0.2989 | Val Loss: 1.8271, Acc: 0.3433\n",
      "Epoch [5/100] - Train Loss: 1.8350, Acc: 0.3326 | Val Loss: 1.7176, Acc: 0.3798\n",
      "Epoch [6/100] - Train Loss: 1.7583, Acc: 0.3593 | Val Loss: 1.6706, Acc: 0.3940\n",
      "Epoch [7/100] - Train Loss: 1.7003, Acc: 0.3800 | Val Loss: 1.6271, Acc: 0.4102\n",
      "Epoch [8/100] - Train Loss: 1.6490, Acc: 0.4000 | Val Loss: 1.5980, Acc: 0.4200\n",
      "Epoch [9/100] - Train Loss: 1.6091, Acc: 0.4142 | Val Loss: 1.5320, Acc: 0.4431\n",
      "Epoch [10/100] - Train Loss: 1.5700, Acc: 0.4327 | Val Loss: 1.5860, Acc: 0.4288\n",
      "Epoch [11/100] - Train Loss: 1.5396, Acc: 0.4438 | Val Loss: 1.4746, Acc: 0.4683\n",
      "Epoch [12/100] - Train Loss: 1.5114, Acc: 0.4560 | Val Loss: 1.4374, Acc: 0.4817\n",
      "Epoch [13/100] - Train Loss: 1.4785, Acc: 0.4661 | Val Loss: 1.3849, Acc: 0.4952\n",
      "Epoch [14/100] - Train Loss: 1.4598, Acc: 0.4717 | Val Loss: 1.3746, Acc: 0.5000\n",
      "Epoch [15/100] - Train Loss: 1.4380, Acc: 0.4789 | Val Loss: 1.3356, Acc: 0.5177\n",
      "Epoch [16/100] - Train Loss: 1.4172, Acc: 0.4904 | Val Loss: 1.3667, Acc: 0.5080\n",
      "Epoch [17/100] - Train Loss: 1.3879, Acc: 0.5026 | Val Loss: 1.2915, Acc: 0.5308\n",
      "Epoch [18/100] - Train Loss: 1.3655, Acc: 0.5100 | Val Loss: 1.2770, Acc: 0.5387\n",
      "Epoch [19/100] - Train Loss: 1.3498, Acc: 0.5179 | Val Loss: 1.3052, Acc: 0.5217\n",
      "Epoch [20/100] - Train Loss: 1.3240, Acc: 0.5275 | Val Loss: 1.3034, Acc: 0.5249\n",
      "Epoch [21/100] - Train Loss: 1.3070, Acc: 0.5323 | Val Loss: 1.2425, Acc: 0.5485\n",
      "Epoch [22/100] - Train Loss: 1.2819, Acc: 0.5416 | Val Loss: 1.2044, Acc: 0.5689\n",
      "Epoch [23/100] - Train Loss: 1.2682, Acc: 0.5483 | Val Loss: 1.1687, Acc: 0.5780\n",
      "Epoch [24/100] - Train Loss: 1.2442, Acc: 0.5554 | Val Loss: 1.1939, Acc: 0.5700\n",
      "Epoch [25/100] - Train Loss: 1.2250, Acc: 0.5615 | Val Loss: 1.1844, Acc: 0.5758\n",
      "Epoch [26/100] - Train Loss: 1.2117, Acc: 0.5670 | Val Loss: 1.1323, Acc: 0.6020\n",
      "Epoch [27/100] - Train Loss: 1.1802, Acc: 0.5763 | Val Loss: 1.1361, Acc: 0.5903\n",
      "Epoch [28/100] - Train Loss: 1.1604, Acc: 0.5857 | Val Loss: 1.0968, Acc: 0.6054\n",
      "Epoch [29/100] - Train Loss: 1.1420, Acc: 0.5966 | Val Loss: 1.1537, Acc: 0.5901\n",
      "Epoch [30/100] - Train Loss: 1.1241, Acc: 0.6042 | Val Loss: 1.0821, Acc: 0.6161\n",
      "Epoch [31/100] - Train Loss: 1.1068, Acc: 0.6066 | Val Loss: 1.1060, Acc: 0.6134\n",
      "Epoch [32/100] - Train Loss: 1.0913, Acc: 0.6119 | Val Loss: 1.0795, Acc: 0.6133\n",
      "Epoch [33/100] - Train Loss: 1.0655, Acc: 0.6244 | Val Loss: 1.0344, Acc: 0.6353\n",
      "Epoch [34/100] - Train Loss: 1.0499, Acc: 0.6280 | Val Loss: 1.0149, Acc: 0.6403\n",
      "Epoch [35/100] - Train Loss: 1.0341, Acc: 0.6332 | Val Loss: 1.0025, Acc: 0.6434\n",
      "Epoch [36/100] - Train Loss: 1.0151, Acc: 0.6406 | Val Loss: 1.0312, Acc: 0.6375\n",
      "Epoch [37/100] - Train Loss: 1.0045, Acc: 0.6443 | Val Loss: 0.9864, Acc: 0.6459\n",
      "Epoch [38/100] - Train Loss: 0.9810, Acc: 0.6538 | Val Loss: 0.9761, Acc: 0.6513\n",
      "Epoch [39/100] - Train Loss: 0.9640, Acc: 0.6593 | Val Loss: 0.9627, Acc: 0.6610\n",
      "Epoch [40/100] - Train Loss: 0.9516, Acc: 0.6591 | Val Loss: 0.9706, Acc: 0.6545\n",
      "Epoch [41/100] - Train Loss: 0.9345, Acc: 0.6710 | Val Loss: 0.9347, Acc: 0.6699\n",
      "Epoch [42/100] - Train Loss: 0.9198, Acc: 0.6740 | Val Loss: 0.9451, Acc: 0.6653\n",
      "Epoch [43/100] - Train Loss: 0.9048, Acc: 0.6801 | Val Loss: 0.9402, Acc: 0.6679\n",
      "Epoch [44/100] - Train Loss: 0.8968, Acc: 0.6836 | Val Loss: 1.0039, Acc: 0.6499\n",
      "Epoch [45/100] - Train Loss: 0.8772, Acc: 0.6888 | Val Loss: 0.9090, Acc: 0.6816\n",
      "Epoch [46/100] - Train Loss: 0.8618, Acc: 0.6964 | Val Loss: 0.9128, Acc: 0.6796\n",
      "Epoch [47/100] - Train Loss: 0.8460, Acc: 0.7016 | Val Loss: 0.9076, Acc: 0.6790\n",
      "Epoch [48/100] - Train Loss: 0.8333, Acc: 0.7058 | Val Loss: 0.8800, Acc: 0.6885\n",
      "Epoch [49/100] - Train Loss: 0.8241, Acc: 0.7110 | Val Loss: 0.8827, Acc: 0.6890\n",
      "Epoch [50/100] - Train Loss: 0.8086, Acc: 0.7149 | Val Loss: 0.8784, Acc: 0.6930\n",
      "Epoch [51/100] - Train Loss: 0.7940, Acc: 0.7182 | Val Loss: 0.8752, Acc: 0.6943\n",
      "Epoch [52/100] - Train Loss: 0.7778, Acc: 0.7257 | Val Loss: 0.8905, Acc: 0.6876\n",
      "Epoch [53/100] - Train Loss: 0.7680, Acc: 0.7248 | Val Loss: 0.8763, Acc: 0.6942\n",
      "Epoch [54/100] - Train Loss: 0.7486, Acc: 0.7338 | Val Loss: 0.8660, Acc: 0.6978\n",
      "Epoch [55/100] - Train Loss: 0.7458, Acc: 0.7374 | Val Loss: 0.8773, Acc: 0.6954\n",
      "Epoch [56/100] - Train Loss: 0.7258, Acc: 0.7404 | Val Loss: 0.8825, Acc: 0.6935\n",
      "Epoch [57/100] - Train Loss: 0.7137, Acc: 0.7428 | Val Loss: 0.8573, Acc: 0.7016\n",
      "Epoch [58/100] - Train Loss: 0.7038, Acc: 0.7487 | Val Loss: 0.9407, Acc: 0.6804\n",
      "Epoch [59/100] - Train Loss: 0.6909, Acc: 0.7585 | Val Loss: 0.8507, Acc: 0.7063\n",
      "Epoch [60/100] - Train Loss: 0.6751, Acc: 0.7593 | Val Loss: 0.8630, Acc: 0.7048\n",
      "Epoch [61/100] - Train Loss: 0.6658, Acc: 0.7616 | Val Loss: 0.8737, Acc: 0.7037\n",
      "Epoch [62/100] - Train Loss: 0.6553, Acc: 0.7674 | Val Loss: 0.8835, Acc: 0.6952\n",
      "Epoch [63/100] - Train Loss: 0.6396, Acc: 0.7728 | Val Loss: 0.8495, Acc: 0.7106\n",
      "Epoch [64/100] - Train Loss: 0.6335, Acc: 0.7736 | Val Loss: 0.8463, Acc: 0.7119\n",
      "Epoch [65/100] - Train Loss: 0.6207, Acc: 0.7760 | Val Loss: 0.8520, Acc: 0.7099\n",
      "Epoch [66/100] - Train Loss: 0.6057, Acc: 0.7854 | Val Loss: 0.8465, Acc: 0.7113\n",
      "Epoch [67/100] - Train Loss: 0.5964, Acc: 0.7871 | Val Loss: 0.8747, Acc: 0.7038\n",
      "Epoch [68/100] - Train Loss: 0.5911, Acc: 0.7912 | Val Loss: 0.8892, Acc: 0.7058\n",
      "Epoch [69/100] - Train Loss: 0.5742, Acc: 0.7935 | Val Loss: 0.9677, Acc: 0.6887\n",
      "Epoch [70/100] - Train Loss: 0.5599, Acc: 0.7990 | Val Loss: 0.8590, Acc: 0.7149\n",
      "Epoch [71/100] - Train Loss: 0.5503, Acc: 0.8000 | Val Loss: 0.9505, Acc: 0.6991\n",
      "Epoch [72/100] - Train Loss: 0.5345, Acc: 0.8098 | Val Loss: 0.8939, Acc: 0.7067\n",
      "Epoch [73/100] - Train Loss: 0.5257, Acc: 0.8106 | Val Loss: 0.8625, Acc: 0.7159\n",
      "Epoch [74/100] - Train Loss: 0.5119, Acc: 0.8161 | Val Loss: 0.8593, Acc: 0.7176\n",
      "Epoch [75/100] - Train Loss: 0.5112, Acc: 0.8137 | Val Loss: 0.8626, Acc: 0.7157\n",
      "Epoch [76/100] - Train Loss: 0.4940, Acc: 0.8209 | Val Loss: 0.8733, Acc: 0.7153\n",
      "Epoch [77/100] - Train Loss: 0.4780, Acc: 0.8226 | Val Loss: 0.8974, Acc: 0.7178\n",
      "Epoch [78/100] - Train Loss: 0.4704, Acc: 0.8283 | Val Loss: 0.8830, Acc: 0.7207\n",
      "Epoch [79/100] - Train Loss: 0.4672, Acc: 0.8304 | Val Loss: 0.9196, Acc: 0.7132\n",
      "Epoch [80/100] - Train Loss: 0.4553, Acc: 0.8337 | Val Loss: 0.9033, Acc: 0.7181\n",
      "Epoch [81/100] - Train Loss: 0.4450, Acc: 0.8400 | Val Loss: 0.8943, Acc: 0.7158\n",
      "Epoch [82/100] - Train Loss: 0.4352, Acc: 0.8418 | Val Loss: 0.9207, Acc: 0.7102\n",
      "Epoch [83/100] - Train Loss: 0.4220, Acc: 0.8461 | Val Loss: 0.9777, Acc: 0.7043\n",
      "Epoch [84/100] - Train Loss: 0.4160, Acc: 0.8485 | Val Loss: 0.9291, Acc: 0.7145\n",
      "Epoch [85/100] - Train Loss: 0.4113, Acc: 0.8492 | Val Loss: 0.9156, Acc: 0.7187\n",
      "Epoch [86/100] - Train Loss: 0.4065, Acc: 0.8519 | Val Loss: 0.9146, Acc: 0.7192\n",
      "Epoch [87/100] - Train Loss: 0.3902, Acc: 0.8590 | Val Loss: 0.9310, Acc: 0.7177\n",
      "Epoch [88/100] - Train Loss: 0.3815, Acc: 0.8606 | Val Loss: 0.9198, Acc: 0.7260\n",
      "Epoch [89/100] - Train Loss: 0.3700, Acc: 0.8629 | Val Loss: 0.9363, Acc: 0.7223\n",
      "Epoch [90/100] - Train Loss: 0.3673, Acc: 0.8646 | Val Loss: 0.9597, Acc: 0.7176\n",
      "Epoch [91/100] - Train Loss: 0.3623, Acc: 0.8674 | Val Loss: 0.9943, Acc: 0.7135\n",
      "Epoch [92/100] - Train Loss: 0.3487, Acc: 0.8697 | Val Loss: 0.9683, Acc: 0.7186\n",
      "Epoch [93/100] - Train Loss: 0.3432, Acc: 0.8740 | Val Loss: 0.9565, Acc: 0.7266\n",
      "Epoch [94/100] - Train Loss: 0.3354, Acc: 0.8778 | Val Loss: 0.9936, Acc: 0.7179\n",
      "Epoch [95/100] - Train Loss: 0.3240, Acc: 0.8804 | Val Loss: 0.9586, Acc: 0.7217\n",
      "Epoch [96/100] - Train Loss: 0.3235, Acc: 0.8817 | Val Loss: 1.0049, Acc: 0.7192\n",
      "Epoch [97/100] - Train Loss: 0.3152, Acc: 0.8824 | Val Loss: 1.0390, Acc: 0.7208\n",
      "Epoch [98/100] - Train Loss: 0.3083, Acc: 0.8844 | Val Loss: 1.0143, Acc: 0.7236\n",
      "Epoch [99/100] - Train Loss: 0.3030, Acc: 0.8875 | Val Loss: 1.0210, Acc: 0.7218\n",
      "Epoch [100/100] - Train Loss: 0.2994, Acc: 0.8886 | Val Loss: 1.0065, Acc: 0.7219\n",
      "TESTING COMPLETE!!\n",
      "Test Loss: 1.0019, Test Acc: 0.7248\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       plane       0.78      0.75      0.76      1000\n",
      "         car       0.84      0.82      0.83      1000\n",
      "        bird       0.64      0.62      0.63      1000\n",
      "         cat       0.53      0.55      0.54      1000\n",
      "        deer       0.71      0.65      0.68      1000\n",
      "         dog       0.58      0.70      0.63      1000\n",
      "        frog       0.80      0.76      0.78      1000\n",
      "       horse       0.77      0.76      0.77      1000\n",
      "        ship       0.84      0.83      0.83      1000\n",
      "       truck       0.79      0.80      0.79      1000\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.72      0.73     10000\n",
      "weighted avg       0.73      0.72      0.73     10000\n",
      "\n",
      "DR:  0.6\n",
      "seed: 2\n",
      "Epoch [1/100] - Train Loss: 2.2976, Acc: 0.1269 | Val Loss: 2.2887, Acc: 0.1891\n",
      "Epoch [2/100] - Train Loss: 2.2520, Acc: 0.1917 | Val Loss: 2.1667, Acc: 0.2272\n",
      "Epoch [3/100] - Train Loss: 2.1039, Acc: 0.2341 | Val Loss: 1.9926, Acc: 0.2811\n",
      "Epoch [4/100] - Train Loss: 1.9914, Acc: 0.2737 | Val Loss: 1.8936, Acc: 0.3240\n",
      "Epoch [5/100] - Train Loss: 1.9031, Acc: 0.3127 | Val Loss: 1.7863, Acc: 0.3558\n",
      "Epoch [6/100] - Train Loss: 1.7991, Acc: 0.3509 | Val Loss: 1.6696, Acc: 0.4036\n",
      "Epoch [7/100] - Train Loss: 1.7052, Acc: 0.3840 | Val Loss: 1.5945, Acc: 0.4242\n",
      "Epoch [8/100] - Train Loss: 1.6372, Acc: 0.4048 | Val Loss: 1.5218, Acc: 0.4521\n",
      "Epoch [9/100] - Train Loss: 1.5892, Acc: 0.4218 | Val Loss: 1.4741, Acc: 0.4661\n",
      "Epoch [10/100] - Train Loss: 1.5456, Acc: 0.4377 | Val Loss: 1.5607, Acc: 0.4359\n",
      "Epoch [11/100] - Train Loss: 1.5152, Acc: 0.4479 | Val Loss: 1.4374, Acc: 0.4797\n",
      "Epoch [12/100] - Train Loss: 1.4849, Acc: 0.4612 | Val Loss: 1.3935, Acc: 0.4917\n",
      "Epoch [13/100] - Train Loss: 1.4588, Acc: 0.4716 | Val Loss: 1.3717, Acc: 0.5011\n",
      "Epoch [14/100] - Train Loss: 1.4383, Acc: 0.4792 | Val Loss: 1.3721, Acc: 0.5045\n",
      "Epoch [15/100] - Train Loss: 1.4095, Acc: 0.4911 | Val Loss: 1.3460, Acc: 0.5177\n",
      "Epoch [16/100] - Train Loss: 1.3922, Acc: 0.4976 | Val Loss: 1.3066, Acc: 0.5281\n",
      "Epoch [17/100] - Train Loss: 1.3680, Acc: 0.5043 | Val Loss: 1.3018, Acc: 0.5279\n",
      "Epoch [18/100] - Train Loss: 1.3505, Acc: 0.5173 | Val Loss: 1.2599, Acc: 0.5456\n",
      "Epoch [19/100] - Train Loss: 1.3357, Acc: 0.5205 | Val Loss: 1.2348, Acc: 0.5558\n",
      "Epoch [20/100] - Train Loss: 1.3108, Acc: 0.5294 | Val Loss: 1.2679, Acc: 0.5424\n",
      "Epoch [21/100] - Train Loss: 1.2948, Acc: 0.5353 | Val Loss: 1.2705, Acc: 0.5491\n",
      "Epoch [22/100] - Train Loss: 1.2711, Acc: 0.5415 | Val Loss: 1.2409, Acc: 0.5554\n",
      "Epoch [23/100] - Train Loss: 1.2544, Acc: 0.5548 | Val Loss: 1.1661, Acc: 0.5825\n",
      "Epoch [24/100] - Train Loss: 1.2290, Acc: 0.5633 | Val Loss: 1.1985, Acc: 0.5670\n",
      "Epoch [25/100] - Train Loss: 1.2125, Acc: 0.5677 | Val Loss: 1.2268, Acc: 0.5699\n",
      "Epoch [26/100] - Train Loss: 1.1894, Acc: 0.5769 | Val Loss: 1.1493, Acc: 0.5888\n",
      "Epoch [27/100] - Train Loss: 1.1764, Acc: 0.5795 | Val Loss: 1.1114, Acc: 0.6045\n",
      "Epoch [28/100] - Train Loss: 1.1540, Acc: 0.5903 | Val Loss: 1.0882, Acc: 0.6109\n",
      "Epoch [29/100] - Train Loss: 1.1358, Acc: 0.5959 | Val Loss: 1.1045, Acc: 0.6041\n",
      "Epoch [30/100] - Train Loss: 1.1162, Acc: 0.6022 | Val Loss: 1.0838, Acc: 0.6088\n",
      "Epoch [31/100] - Train Loss: 1.0996, Acc: 0.6057 | Val Loss: 1.0650, Acc: 0.6237\n",
      "Epoch [32/100] - Train Loss: 1.0832, Acc: 0.6153 | Val Loss: 1.0364, Acc: 0.6317\n",
      "Epoch [33/100] - Train Loss: 1.0617, Acc: 0.6242 | Val Loss: 1.0412, Acc: 0.6275\n",
      "Epoch [34/100] - Train Loss: 1.0408, Acc: 0.6274 | Val Loss: 1.0164, Acc: 0.6384\n",
      "Epoch [35/100] - Train Loss: 1.0290, Acc: 0.6348 | Val Loss: 1.0236, Acc: 0.6325\n",
      "Epoch [36/100] - Train Loss: 1.0114, Acc: 0.6425 | Val Loss: 1.0083, Acc: 0.6379\n",
      "Epoch [37/100] - Train Loss: 0.9991, Acc: 0.6459 | Val Loss: 1.0270, Acc: 0.6384\n",
      "Epoch [38/100] - Train Loss: 0.9805, Acc: 0.6555 | Val Loss: 1.0017, Acc: 0.6470\n",
      "Epoch [39/100] - Train Loss: 0.9644, Acc: 0.6575 | Val Loss: 0.9828, Acc: 0.6504\n",
      "Epoch [40/100] - Train Loss: 0.9464, Acc: 0.6640 | Val Loss: 0.9949, Acc: 0.6499\n",
      "Epoch [41/100] - Train Loss: 0.9358, Acc: 0.6663 | Val Loss: 0.9574, Acc: 0.6636\n",
      "Epoch [42/100] - Train Loss: 0.9151, Acc: 0.6756 | Val Loss: 0.9310, Acc: 0.6718\n",
      "Epoch [43/100] - Train Loss: 0.9033, Acc: 0.6810 | Val Loss: 0.9354, Acc: 0.6685\n",
      "Epoch [44/100] - Train Loss: 0.8853, Acc: 0.6892 | Val Loss: 0.9304, Acc: 0.6735\n",
      "Epoch [45/100] - Train Loss: 0.8762, Acc: 0.6892 | Val Loss: 0.9568, Acc: 0.6595\n",
      "Epoch [46/100] - Train Loss: 0.8543, Acc: 0.6982 | Val Loss: 0.9081, Acc: 0.6831\n",
      "Epoch [47/100] - Train Loss: 0.8421, Acc: 0.7006 | Val Loss: 0.9113, Acc: 0.6779\n",
      "Epoch [48/100] - Train Loss: 0.8357, Acc: 0.7062 | Val Loss: 0.9524, Acc: 0.6684\n",
      "Epoch [49/100] - Train Loss: 0.8182, Acc: 0.7118 | Val Loss: 0.8849, Acc: 0.6884\n",
      "Epoch [50/100] - Train Loss: 0.8084, Acc: 0.7166 | Val Loss: 0.9115, Acc: 0.6822\n",
      "Epoch [51/100] - Train Loss: 0.7924, Acc: 0.7176 | Val Loss: 0.8971, Acc: 0.6897\n",
      "Epoch [52/100] - Train Loss: 0.7783, Acc: 0.7245 | Val Loss: 1.0671, Acc: 0.6380\n",
      "Epoch [53/100] - Train Loss: 0.7658, Acc: 0.7303 | Val Loss: 0.8611, Acc: 0.6995\n",
      "Epoch [54/100] - Train Loss: 0.7537, Acc: 0.7305 | Val Loss: 0.8758, Acc: 0.6937\n",
      "Epoch [55/100] - Train Loss: 0.7357, Acc: 0.7407 | Val Loss: 0.9001, Acc: 0.6914\n",
      "Epoch [56/100] - Train Loss: 0.7258, Acc: 0.7412 | Val Loss: 0.8640, Acc: 0.7016\n",
      "Epoch [57/100] - Train Loss: 0.7128, Acc: 0.7475 | Val Loss: 0.8613, Acc: 0.6997\n",
      "Epoch [58/100] - Train Loss: 0.7000, Acc: 0.7516 | Val Loss: 0.8480, Acc: 0.7070\n",
      "Epoch [59/100] - Train Loss: 0.6854, Acc: 0.7555 | Val Loss: 0.8914, Acc: 0.6942\n",
      "Epoch [60/100] - Train Loss: 0.6730, Acc: 0.7609 | Val Loss: 0.8631, Acc: 0.7039\n",
      "Epoch [61/100] - Train Loss: 0.6586, Acc: 0.7692 | Val Loss: 0.8523, Acc: 0.7090\n",
      "Epoch [62/100] - Train Loss: 0.6464, Acc: 0.7705 | Val Loss: 0.8473, Acc: 0.7067\n",
      "Epoch [63/100] - Train Loss: 0.6381, Acc: 0.7727 | Val Loss: 0.8808, Acc: 0.7056\n",
      "Epoch [64/100] - Train Loss: 0.6212, Acc: 0.7783 | Val Loss: 0.9196, Acc: 0.6902\n",
      "Epoch [65/100] - Train Loss: 0.6157, Acc: 0.7806 | Val Loss: 0.9112, Acc: 0.6893\n",
      "Epoch [66/100] - Train Loss: 0.5987, Acc: 0.7870 | Val Loss: 0.8451, Acc: 0.7120\n",
      "Epoch [67/100] - Train Loss: 0.5920, Acc: 0.7887 | Val Loss: 0.8587, Acc: 0.7124\n",
      "Epoch [68/100] - Train Loss: 0.5748, Acc: 0.7955 | Val Loss: 0.8593, Acc: 0.7118\n",
      "Epoch [69/100] - Train Loss: 0.5628, Acc: 0.7997 | Val Loss: 0.8598, Acc: 0.7127\n",
      "Epoch [70/100] - Train Loss: 0.5522, Acc: 0.8025 | Val Loss: 0.8672, Acc: 0.7152\n",
      "Epoch [71/100] - Train Loss: 0.5462, Acc: 0.8055 | Val Loss: 0.8400, Acc: 0.7211\n",
      "Epoch [72/100] - Train Loss: 0.5268, Acc: 0.8097 | Val Loss: 0.9465, Acc: 0.7021\n",
      "Epoch [73/100] - Train Loss: 0.5195, Acc: 0.8147 | Val Loss: 0.8791, Acc: 0.7095\n",
      "Epoch [74/100] - Train Loss: 0.5084, Acc: 0.8169 | Val Loss: 0.8837, Acc: 0.7134\n",
      "Epoch [75/100] - Train Loss: 0.5031, Acc: 0.8173 | Val Loss: 0.8376, Acc: 0.7226\n",
      "Epoch [76/100] - Train Loss: 0.4898, Acc: 0.8225 | Val Loss: 0.8507, Acc: 0.7209\n",
      "Epoch [77/100] - Train Loss: 0.4720, Acc: 0.8302 | Val Loss: 0.9298, Acc: 0.7036\n",
      "Epoch [78/100] - Train Loss: 0.4670, Acc: 0.8338 | Val Loss: 0.8977, Acc: 0.7143\n",
      "Epoch [79/100] - Train Loss: 0.4666, Acc: 0.8335 | Val Loss: 0.8798, Acc: 0.7208\n",
      "Epoch [80/100] - Train Loss: 0.4479, Acc: 0.8395 | Val Loss: 0.9402, Acc: 0.7070\n",
      "Epoch [81/100] - Train Loss: 0.4407, Acc: 0.8409 | Val Loss: 0.9195, Acc: 0.7107\n",
      "Epoch [82/100] - Train Loss: 0.4293, Acc: 0.8433 | Val Loss: 0.9133, Acc: 0.7184\n",
      "Epoch [83/100] - Train Loss: 0.4241, Acc: 0.8466 | Val Loss: 0.9876, Acc: 0.6991\n",
      "Epoch [84/100] - Train Loss: 0.3987, Acc: 0.8560 | Val Loss: 0.9101, Acc: 0.7204\n",
      "Epoch [85/100] - Train Loss: 0.4019, Acc: 0.8547 | Val Loss: 0.8931, Acc: 0.7228\n",
      "Epoch [86/100] - Train Loss: 0.3987, Acc: 0.8556 | Val Loss: 0.9586, Acc: 0.7167\n",
      "Epoch [87/100] - Train Loss: 0.3864, Acc: 0.8576 | Val Loss: 0.9340, Acc: 0.7225\n",
      "Epoch [88/100] - Train Loss: 0.3754, Acc: 0.8639 | Val Loss: 0.9188, Acc: 0.7264\n",
      "Epoch [89/100] - Train Loss: 0.3656, Acc: 0.8690 | Val Loss: 0.9332, Acc: 0.7206\n",
      "Epoch [90/100] - Train Loss: 0.3552, Acc: 0.8700 | Val Loss: 0.9416, Acc: 0.7191\n",
      "Epoch [91/100] - Train Loss: 0.3479, Acc: 0.8723 | Val Loss: 0.9481, Acc: 0.7222\n",
      "Epoch [92/100] - Train Loss: 0.3393, Acc: 0.8773 | Val Loss: 0.9474, Acc: 0.7236\n",
      "Epoch [93/100] - Train Loss: 0.3301, Acc: 0.8793 | Val Loss: 0.9888, Acc: 0.7217\n",
      "Epoch [94/100] - Train Loss: 0.3367, Acc: 0.8777 | Val Loss: 0.9918, Acc: 0.7167\n",
      "Epoch [95/100] - Train Loss: 0.3193, Acc: 0.8837 | Val Loss: 0.9745, Acc: 0.7255\n",
      "Epoch [96/100] - Train Loss: 0.3119, Acc: 0.8868 | Val Loss: 0.9883, Acc: 0.7263\n",
      "Epoch [97/100] - Train Loss: 0.3090, Acc: 0.8860 | Val Loss: 1.0394, Acc: 0.7185\n",
      "Epoch [98/100] - Train Loss: 0.3037, Acc: 0.8894 | Val Loss: 1.0358, Acc: 0.7205\n",
      "Epoch [99/100] - Train Loss: 0.2940, Acc: 0.8940 | Val Loss: 1.0135, Acc: 0.7281\n",
      "Epoch [100/100] - Train Loss: 0.2864, Acc: 0.8957 | Val Loss: 1.0226, Acc: 0.7258\n",
      "TESTING COMPLETE!!\n",
      "Test Loss: 1.0392, Test Acc: 0.7236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       plane       0.73      0.80      0.76      1000\n",
      "         car       0.86      0.83      0.84      1000\n",
      "        bird       0.68      0.55      0.61      1000\n",
      "         cat       0.53      0.53      0.53      1000\n",
      "        deer       0.62      0.70      0.66      1000\n",
      "         dog       0.57      0.70      0.63      1000\n",
      "        frog       0.81      0.76      0.79      1000\n",
      "       horse       0.81      0.74      0.78      1000\n",
      "        ship       0.88      0.80      0.84      1000\n",
      "       truck       0.80      0.82      0.81      1000\n",
      "\n",
      "    accuracy                           0.72     10000\n",
      "   macro avg       0.73      0.72      0.72     10000\n",
      "weighted avg       0.73      0.72      0.72     10000\n",
      "\n",
      "DR:  0.6\n",
      "seed: 3\n",
      "Epoch [1/100] - Train Loss: 2.2991, Acc: 0.1093 | Val Loss: 2.2937, Acc: 0.1211\n",
      "Epoch [2/100] - Train Loss: 2.2786, Acc: 0.1566 | Val Loss: 2.2427, Acc: 0.2295\n",
      "Epoch [3/100] - Train Loss: 2.1575, Acc: 0.2165 | Val Loss: 2.0316, Acc: 0.2885\n",
      "Epoch [4/100] - Train Loss: 2.0000, Acc: 0.2742 | Val Loss: 1.8919, Acc: 0.3218\n",
      "Epoch [5/100] - Train Loss: 1.8955, Acc: 0.3134 | Val Loss: 1.7961, Acc: 0.3572\n",
      "Epoch [6/100] - Train Loss: 1.8078, Acc: 0.3410 | Val Loss: 1.6893, Acc: 0.3810\n",
      "Epoch [7/100] - Train Loss: 1.7386, Acc: 0.3643 | Val Loss: 1.6184, Acc: 0.4150\n",
      "Epoch [8/100] - Train Loss: 1.6879, Acc: 0.3848 | Val Loss: 1.6238, Acc: 0.4150\n",
      "Epoch [9/100] - Train Loss: 1.6414, Acc: 0.4011 | Val Loss: 1.5680, Acc: 0.4315\n",
      "Epoch [10/100] - Train Loss: 1.6054, Acc: 0.4184 | Val Loss: 1.5413, Acc: 0.4457\n",
      "Epoch [11/100] - Train Loss: 1.5669, Acc: 0.4279 | Val Loss: 1.4793, Acc: 0.4690\n",
      "Epoch [12/100] - Train Loss: 1.5383, Acc: 0.4431 | Val Loss: 1.4339, Acc: 0.4770\n",
      "Epoch [13/100] - Train Loss: 1.5072, Acc: 0.4533 | Val Loss: 1.3975, Acc: 0.4929\n",
      "Epoch [14/100] - Train Loss: 1.4779, Acc: 0.4617 | Val Loss: 1.3969, Acc: 0.4909\n",
      "Epoch [15/100] - Train Loss: 1.4561, Acc: 0.4745 | Val Loss: 1.3597, Acc: 0.5025\n",
      "Epoch [16/100] - Train Loss: 1.4289, Acc: 0.4832 | Val Loss: 1.3348, Acc: 0.5166\n",
      "Epoch [17/100] - Train Loss: 1.4024, Acc: 0.4953 | Val Loss: 1.3109, Acc: 0.5233\n",
      "Epoch [18/100] - Train Loss: 1.3804, Acc: 0.5017 | Val Loss: 1.2812, Acc: 0.5316\n",
      "Epoch [19/100] - Train Loss: 1.3537, Acc: 0.5131 | Val Loss: 1.2662, Acc: 0.5447\n",
      "Epoch [20/100] - Train Loss: 1.3374, Acc: 0.5182 | Val Loss: 1.2632, Acc: 0.5470\n",
      "Epoch [21/100] - Train Loss: 1.3113, Acc: 0.5300 | Val Loss: 1.2436, Acc: 0.5540\n",
      "Epoch [22/100] - Train Loss: 1.2877, Acc: 0.5350 | Val Loss: 1.2202, Acc: 0.5538\n",
      "Epoch [23/100] - Train Loss: 1.2686, Acc: 0.5427 | Val Loss: 1.2572, Acc: 0.5472\n",
      "Epoch [24/100] - Train Loss: 1.2472, Acc: 0.5501 | Val Loss: 1.1862, Acc: 0.5712\n",
      "Epoch [25/100] - Train Loss: 1.2284, Acc: 0.5615 | Val Loss: 1.1616, Acc: 0.5853\n",
      "Epoch [26/100] - Train Loss: 1.2067, Acc: 0.5687 | Val Loss: 1.1336, Acc: 0.5982\n",
      "Epoch [27/100] - Train Loss: 1.1886, Acc: 0.5753 | Val Loss: 1.1173, Acc: 0.5979\n",
      "Epoch [28/100] - Train Loss: 1.1675, Acc: 0.5835 | Val Loss: 1.1084, Acc: 0.6011\n",
      "Epoch [29/100] - Train Loss: 1.1456, Acc: 0.5902 | Val Loss: 1.1612, Acc: 0.5836\n",
      "Epoch [30/100] - Train Loss: 1.1277, Acc: 0.5975 | Val Loss: 1.0788, Acc: 0.6172\n",
      "Epoch [31/100] - Train Loss: 1.1048, Acc: 0.6093 | Val Loss: 1.0533, Acc: 0.6254\n",
      "Epoch [32/100] - Train Loss: 1.0936, Acc: 0.6125 | Val Loss: 1.0548, Acc: 0.6242\n",
      "Epoch [33/100] - Train Loss: 1.0679, Acc: 0.6225 | Val Loss: 1.0193, Acc: 0.6382\n",
      "Epoch [34/100] - Train Loss: 1.0582, Acc: 0.6275 | Val Loss: 1.0400, Acc: 0.6307\n",
      "Epoch [35/100] - Train Loss: 1.0370, Acc: 0.6323 | Val Loss: 0.9980, Acc: 0.6468\n",
      "Epoch [36/100] - Train Loss: 1.0177, Acc: 0.6421 | Val Loss: 0.9915, Acc: 0.6499\n",
      "Epoch [37/100] - Train Loss: 1.0023, Acc: 0.6483 | Val Loss: 0.9688, Acc: 0.6548\n",
      "Epoch [38/100] - Train Loss: 0.9800, Acc: 0.6564 | Val Loss: 0.9787, Acc: 0.6539\n",
      "Epoch [39/100] - Train Loss: 0.9604, Acc: 0.6595 | Val Loss: 0.9434, Acc: 0.6647\n",
      "Epoch [40/100] - Train Loss: 0.9481, Acc: 0.6634 | Val Loss: 0.9599, Acc: 0.6614\n",
      "Epoch [41/100] - Train Loss: 0.9311, Acc: 0.6688 | Val Loss: 0.9546, Acc: 0.6596\n",
      "Epoch [42/100] - Train Loss: 0.9181, Acc: 0.6733 | Val Loss: 0.9509, Acc: 0.6623\n",
      "Epoch [43/100] - Train Loss: 0.9025, Acc: 0.6803 | Val Loss: 0.9144, Acc: 0.6754\n",
      "Epoch [44/100] - Train Loss: 0.8917, Acc: 0.6839 | Val Loss: 0.9142, Acc: 0.6768\n",
      "Epoch [45/100] - Train Loss: 0.8728, Acc: 0.6934 | Val Loss: 0.8986, Acc: 0.6829\n",
      "Epoch [46/100] - Train Loss: 0.8625, Acc: 0.6937 | Val Loss: 0.8872, Acc: 0.6879\n",
      "Epoch [47/100] - Train Loss: 0.8461, Acc: 0.6982 | Val Loss: 0.9099, Acc: 0.6769\n",
      "Epoch [48/100] - Train Loss: 0.8313, Acc: 0.7065 | Val Loss: 0.8823, Acc: 0.6897\n",
      "Epoch [49/100] - Train Loss: 0.8131, Acc: 0.7134 | Val Loss: 0.8836, Acc: 0.6919\n",
      "Epoch [50/100] - Train Loss: 0.8071, Acc: 0.7166 | Val Loss: 0.8761, Acc: 0.6921\n",
      "Epoch [51/100] - Train Loss: 0.7933, Acc: 0.7187 | Val Loss: 0.8787, Acc: 0.6908\n",
      "Epoch [52/100] - Train Loss: 0.7774, Acc: 0.7251 | Val Loss: 0.8646, Acc: 0.6969\n",
      "Epoch [53/100] - Train Loss: 0.7612, Acc: 0.7304 | Val Loss: 0.8973, Acc: 0.6852\n",
      "Epoch [54/100] - Train Loss: 0.7523, Acc: 0.7337 | Val Loss: 0.8755, Acc: 0.6925\n",
      "Epoch [55/100] - Train Loss: 0.7385, Acc: 0.7383 | Val Loss: 0.8560, Acc: 0.7030\n",
      "Epoch [56/100] - Train Loss: 0.7248, Acc: 0.7434 | Val Loss: 0.8825, Acc: 0.6930\n",
      "Epoch [57/100] - Train Loss: 0.7112, Acc: 0.7493 | Val Loss: 0.8635, Acc: 0.7053\n",
      "Epoch [58/100] - Train Loss: 0.6991, Acc: 0.7544 | Val Loss: 0.8545, Acc: 0.7043\n",
      "Epoch [59/100] - Train Loss: 0.6901, Acc: 0.7519 | Val Loss: 0.8415, Acc: 0.7070\n",
      "Epoch [60/100] - Train Loss: 0.6758, Acc: 0.7580 | Val Loss: 0.8564, Acc: 0.7029\n",
      "Epoch [61/100] - Train Loss: 0.6606, Acc: 0.7648 | Val Loss: 0.8435, Acc: 0.7085\n",
      "Epoch [62/100] - Train Loss: 0.6508, Acc: 0.7683 | Val Loss: 0.8431, Acc: 0.7088\n",
      "Epoch [63/100] - Train Loss: 0.6388, Acc: 0.7697 | Val Loss: 0.8708, Acc: 0.7034\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m     31\u001b[0m optimiser \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mlearning_rate)\n\u001b[1;32m---> 33\u001b[0m model, train_epoch_losses, train_epoch_accuracy, val_epoch_losses, val_epoch_accuracy, _,_ \u001b[38;5;241m=\u001b[39m run_training_and_validation(model, device, learning_rate, num_epochs, criterion, optimiser, train_dataloader, val_dataloader, metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, manual_lr_schedule\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     34\u001b[0m epoch_train_losses_by_run\u001b[38;5;241m.\u001b[39mappend(train_epoch_losses)\n\u001b[0;32m     35\u001b[0m epoch_val_losses_by_run\u001b[38;5;241m.\u001b[39mappend(val_epoch_losses)\n",
      "File \u001b[1;32mc:\\Users\\rd81\\OneDrive - University of Sussex\\Desktop\\NN_2024_assessment_2504\\utils.py:74\u001b[0m, in \u001b[0;36mrun_training_and_validation\u001b[1;34m(model, device, initial_lr, num_epochs, criterion, optimiser, train_dataloader, val_dataloader, metrics, manual_lr_schedule, scheduler_func, plot)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (images, labels) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[0;32m     73\u001b[0m     images \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 74\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     76\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m     77\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# exp 2 pt 1 - drop out exploration\n",
    "from utils import DropoutNet\n",
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "random_seeds = list(range(5))\n",
    "dropout_rates_for_experiment = [0, 0.2, 0.4, 0.6, 0.8]\n",
    "averaged_results = {dr:{} for dr in dropout_rates_for_experiment}\n",
    "\n",
    "path_to_save = f'./run_data/dropout/corrected_dropout_data_{num_epochs}_epochs.json'\n",
    "path_to_load = f'./run_data/dropout/corrected_dropout_data_{num_epochs}_epochs.json'\n",
    "save_experiment = True\n",
    "\n",
    "\n",
    "for dropout_rate in dropout_rates_for_experiment:\n",
    "    print('DR: ', dropout_rate) \n",
    "    epoch_train_losses_by_run = []\n",
    "    epoch_val_losses_by_run = []\n",
    "    epoch_train_accuracies_by_run = []\n",
    "    epoch_val_accuracies_by_run = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    reports = []\n",
    "    \n",
    "    for random_seed in random_seeds:\n",
    "        print('DR: ', dropout_rate) \n",
    "        print('seed:', random_seed)\n",
    "        torch.manual_seed(random_seed)\n",
    "\n",
    "        model = DropoutNet(dropout_rate).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimiser = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        model, train_epoch_losses, train_epoch_accuracy, val_epoch_losses, val_epoch_accuracy, _,_ = run_training_and_validation(model, device, learning_rate, num_epochs, criterion, optimiser, train_dataloader, val_dataloader, metrics = False, manual_lr_schedule=False)\n",
    "        epoch_train_losses_by_run.append(train_epoch_losses)\n",
    "        epoch_val_losses_by_run.append(val_epoch_losses)\n",
    "        epoch_train_accuracies_by_run.append(train_epoch_accuracy)\n",
    "        epoch_val_accuracies_by_run.append(val_epoch_accuracy)\n",
    "        \n",
    "        test_loss, test_accuracy, report = run_testing(model, device, criterion, test_dataloader)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        reports.append(report)\n",
    "        \n",
    "    average_train_losses = [sum(epoch_losses) / len(epoch_losses) for epoch_losses in zip(*epoch_train_losses_by_run)]\n",
    "    average_val_losses = [sum(epoch_losses) / len(epoch_losses) for epoch_losses in zip(*epoch_val_losses_by_run)]\n",
    "    average_train_accuracies = [sum(epoch_accuracies) / len(epoch_accuracies) for epoch_accuracies in zip(*epoch_train_accuracies_by_run)]\n",
    "    average_val_accuracies =  [sum(epoch_accuracies) / len(epoch_accuracies) for epoch_accuracies in zip(*epoch_val_accuracies_by_run)]\n",
    "    average_test_loss = sum(test_losses)/len(test_losses)\n",
    "    average_test_accuracy = sum(test_accuracies)/len(test_accuracies)\n",
    "    \n",
    "    averaged_results[dropout_rate] = {'seeds':random_seeds,'av_train_losses': average_train_losses,\n",
    "                                       'av_val_losses': average_val_losses,\n",
    "                                       'av_train_acc': average_train_accuracies,\n",
    "                                       'av_val_acc': average_val_accuracies,\n",
    "                                       'all_train_losses':epoch_train_losses_by_run,\n",
    "                                       'all_val_losses': epoch_val_losses_by_run,\n",
    "                                       'all_train_accuracies': epoch_train_accuracies_by_run,\n",
    "                                       'all_val_accuracies': epoch_val_accuracies_by_run,\n",
    "                                       'all_test_losses':test_losses, \n",
    "                                       'all_test_accuracies':test_accuracies,\n",
    "                                       'av_test_loss': average_test_loss,\n",
    "                                       'av_test_accuracy':average_test_accuracy}\n",
    "    print('average for ')\n",
    "    print('DR: ', dropout_rate) \n",
    "    plot_single_train_val_smoothed(average_train_losses,average_val_losses,average_train_accuracies,average_val_accuracies, num_epochs, smoothing_window=3, title=f'DROPOUT: {dropout_rate}')\n",
    "\n",
    "if save_experiment:\n",
    "    with open(path_to_save, 'w') as file:\n",
    "        json.dump(averaged_results, file, indent=4)  # 'indent' makes the output formatted and easier to read\n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import display_accuracy_heatmap, print_sep_runs_from_file\n",
    "# path_to_load = f'./run_data/dropout_data_50_epochs.json'\n",
    "\n",
    "# display_accuracy_heatmap(path_to_load)\n",
    "# man_ticks =[1, 0.1, 3, 0.25]\n",
    "# print_sep_runs_from_file(path_to_load, 50, manual_ticks=True, ticks=man_ticks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPR 2 PART 2\n",
    "# summary:\n",
    "# swap the two data sets\n",
    "# To swap the datasets between the two dataloaders\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "original_train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "original_val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "swapped_train_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "swapped_val_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the non-dropout model (like inialise it fresh)\n",
    "# train them on original data and save them as model\n",
    "\n",
    "\n",
    "best_dropout_rate = 0.6\n",
    "num_epochs = 100\n",
    "learning_rate = 0.1\n",
    "random_seeds = list(range(5))\n",
    "\n",
    "\n",
    "path_to_save = f'./run_data/dropout/corrected_dropout_model_comparison_original_data_{num_epochs}_epochs.json'\n",
    "path_to_load = f'./run_data/dropout/corrected_dropout_model_comparison_original_data_{num_epochs}_epochs.json'\n",
    "\n",
    "models = [0, 1]\n",
    "averaged_results = {i:{} for i in models}\n",
    "\n",
    "save_experiment = True\n",
    "\n",
    "# train them both on the original data\n",
    "for i, model in enumerate(models):\n",
    "    epoch_train_losses_by_run = []\n",
    "    epoch_val_losses_by_run = []\n",
    "    epoch_train_accuracies_by_run = []\n",
    "    epoch_val_accuracies_by_run = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    reports = []\n",
    "    \n",
    "    for random_seed in random_seeds:\n",
    "        print('MODEL: ', i) \n",
    "        print('seed:', random_seed)\n",
    "        model = BaselineNet(random_seed=random_seed) if i == 0 else DropoutNet(dropout_rate=best_dropout_rate, random_seed=random_seed)\n",
    "        model.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimiser = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "        model, train_epoch_losses, train_epoch_accuracy, val_epoch_losses, val_epoch_accuracy, _,_ = run_training_and_validation(model, device, learning_rate, num_epochs, criterion, optimiser, original_train_dataloader, original_val_dataloader, metrics = False, manual_lr_schedule=False)\n",
    "        epoch_train_losses_by_run.append(train_epoch_losses)\n",
    "        epoch_val_losses_by_run.append(val_epoch_losses)\n",
    "        epoch_train_accuracies_by_run.append(train_epoch_accuracy)\n",
    "        epoch_val_accuracies_by_run.append(val_epoch_accuracy)\n",
    "        \n",
    "        test_loss, test_accuracy, report = run_testing(model, device, criterion, test_dataloader)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        reports.append(report)\n",
    "        \n",
    "    average_train_losses = [sum(epoch_losses) / len(epoch_losses) for epoch_losses in zip(*epoch_train_losses_by_run)]\n",
    "    average_val_losses = [sum(epoch_losses) / len(epoch_losses) for epoch_losses in zip(*epoch_val_losses_by_run)]\n",
    "    average_train_accuracies = [sum(epoch_accuracies) / len(epoch_accuracies) for epoch_accuracies in zip(*epoch_train_accuracies_by_run)]\n",
    "    average_val_accuracies =  [sum(epoch_accuracies) / len(epoch_accuracies) for epoch_accuracies in zip(*epoch_val_accuracies_by_run)]\n",
    "    average_test_loss = sum(test_losses)/len(test_losses)\n",
    "    average_test_accuracy = sum(test_accuracies)/len(test_accuracies)\n",
    "    \n",
    "    averaged_results[i] = {'seeds':random_seeds,'av_train_losses': average_train_losses,\n",
    "                                       'av_val_losses': average_val_losses,\n",
    "                                       'av_train_acc': average_train_accuracies,\n",
    "                                       'av_val_acc': average_val_accuracies,\n",
    "                                       'all_train_losses':epoch_train_losses_by_run,\n",
    "                                       'all_val_losses': epoch_val_losses_by_run,\n",
    "                                       'all_train_accuracies': epoch_train_accuracies_by_run,\n",
    "                                       'all_val_accuracies': epoch_val_accuracies_by_run,\n",
    "                                       'all_test_losses':test_losses, \n",
    "                                       'all_test_accuracies':test_accuracies,\n",
    "                                       'av_test_loss': average_test_loss,\n",
    "                                       'av_test_accuracy':average_test_accuracy}\n",
    "    print('average for ')\n",
    "    print('Model: ', i) \n",
    "    plot_single_train_val_smoothed(average_train_losses,average_val_losses,average_train_accuracies,average_val_accuracies, num_epochs, smoothing_window=3, title=f'MODEL: {i}')\n",
    "    \n",
    "    # save last version of model to disk for retraining    \n",
    "    torch.save(model, f'./models/trained_model_{i}.pth')\n",
    "\n",
    "    \n",
    "if save_experiment:\n",
    "    with open(path_to_save, 'w') as file:\n",
    "        json.dump(averaged_results, file, indent=4)  # 'indent' makes the output formatted and easier to read\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THEM AS NEW MODELS FOR RETRAINING \n",
    "\n",
    "pretrained_model_non_dropout = torch.load('./models/trained_model_0.pth', pretrained=True)\n",
    "pretrained_model_best_dropout = torch.load('./models/trained_model_1.pth', pretrained=True)\n",
    "\n",
    "\n",
    "pretrained_model_non_dropout.fc1 = nn.Linear(in_features=128 * 4 * 4, out_features=128)\n",
    "pretrained_model_best_dropout.fc1 = nn.Linear(in_features=128 * 4 * 4, out_features=128)\n",
    "\n",
    "\n",
    "pretrained_model_non_dropout.fc2 = nn.Linear(in_features=128, out_features=10)\n",
    "pretrained_model_best_dropout.fc2 = nn.Linear(in_features=128, out_features=10)\n",
    "\n",
    "# do transfer learning\n",
    "\n",
    "num_epochs = 50\n",
    "learning_rate = 0.1\n",
    "random_seeds = list(range(5))\n",
    "\n",
    "averaged_results = {dr:{} for dr in dropout_rates_for_experiment}\n",
    "\n",
    "path_to_save = f'./run_data/dropout/corrected_dropout_model_comparison_swapped_data_{num_epochs}_epochs.json'\n",
    "path_to_load = f'./run_data/dropout/corrected_dropout_model_comparison_swapped_data_{num_epochs}_epochs.json'\n",
    "\n",
    "models = [0, 1]\n",
    "averaged_results = {i:{} for i in models}\n",
    "\n",
    "save_experiment = True\n",
    "\n",
    "# train them both on the swapped train and val data - test data same\n",
    "for i, model in enumerate(models):\n",
    "    epoch_train_losses_by_run = []\n",
    "    epoch_val_losses_by_run = []\n",
    "    epoch_train_accuracies_by_run = []\n",
    "    epoch_val_accuracies_by_run = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    reports = []\n",
    "    \n",
    "    for random_seed in random_seeds:\n",
    "        print('MODEL: ', i) \n",
    "        print('seed:', random_seed)\n",
    "        model = pretrained_model_non_dropout if i == 0 else pretrained_model_best_dropout\n",
    "        model.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimiser = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "        model, train_epoch_losses, train_epoch_accuracy, val_epoch_losses, val_epoch_accuracy, _,_ = run_training_and_validation(model, device, learning_rate, num_epochs, criterion, optimiser, swapped_train_dataloader, swapped_val_dataloader, metrics = False, manual_lr_schedule=False)\n",
    "        epoch_train_losses_by_run.append(train_epoch_losses)\n",
    "        epoch_val_losses_by_run.append(val_epoch_losses)\n",
    "        epoch_train_accuracies_by_run.append(train_epoch_accuracy)\n",
    "        epoch_val_accuracies_by_run.append(val_epoch_accuracy)\n",
    "        \n",
    "        test_loss, test_accuracy, report = run_testing(model, device, criterion, test_dataloader)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        reports.append(report)\n",
    "        \n",
    "    average_train_losses = [sum(epoch_losses) / len(epoch_losses) for epoch_losses in zip(*epoch_train_losses_by_run)]\n",
    "    average_val_losses = [sum(epoch_losses) / len(epoch_losses) for epoch_losses in zip(*epoch_val_losses_by_run)]\n",
    "    average_train_accuracies = [sum(epoch_accuracies) / len(epoch_accuracies) for epoch_accuracies in zip(*epoch_train_accuracies_by_run)]\n",
    "    average_val_accuracies =  [sum(epoch_accuracies) / len(epoch_accuracies) for epoch_accuracies in zip(*epoch_val_accuracies_by_run)]\n",
    "    average_test_loss = sum(test_losses)/len(test_losses)\n",
    "    average_test_accuracy = sum(test_accuracies)/len(test_accuracies)\n",
    "    \n",
    "    averaged_results[i] = {'seeds':random_seeds,'av_train_losses': average_train_losses,\n",
    "                                       'av_val_losses': average_val_losses,\n",
    "                                       'av_train_acc': average_train_accuracies,\n",
    "                                       'av_val_acc': average_val_accuracies,\n",
    "                                       'all_train_losses':epoch_train_losses_by_run,\n",
    "                                       'all_val_losses': epoch_val_losses_by_run,\n",
    "                                       'all_train_accuracies': epoch_train_accuracies_by_run,\n",
    "                                       'all_val_accuracies': epoch_val_accuracies_by_run,\n",
    "                                       'all_test_losses':test_losses, \n",
    "                                       'all_test_accuracies':test_accuracies,\n",
    "                                       'av_test_loss': average_test_loss,\n",
    "                                       'av_test_accuracy':average_test_accuracy}\n",
    "    print('average for ')\n",
    "    print('Model: ', i) \n",
    "    plot_single_train_val_smoothed(average_train_losses,average_val_losses,average_train_accuracies,average_val_accuracies, num_epochs, smoothing_window=3, title=f'MODEL: {i}')\n",
    "    \n",
    "\n",
    "\n",
    "if save_experiment:\n",
    "    with open(path_to_save, 'w') as file:\n",
    "        json.dump(averaged_results, file, indent=4)  # 'indent' makes the output formatted and easier to read\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. 5 COMPARE AND CONTRAST!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EX 3\n",
    "Investigate the quality of gradient flow through your network.\n",
    "\n",
    "\n",
    "*First*, for the model that does not use Dropout, record gradients for the optimised parameters (i.e.\n",
    "dL/dw) in each layer of your model. \n",
    "\n",
    "Record the gradients over the first 5 episodes of training.\n",
    "Build a separate record of gradients over the final 5 episodes of training. \n",
    "Produce plots to show how the mean and standard deviation of gradients change as a function of layer number, for both the beginning (first 5 episodes) and the end (final 5 episodes) of training.\n",
    "\n",
    "*Second*, using the best performing, non-zero Dropout rate from Experiment 2, perform the same calculations to compute the mean and stand deviation of the gradients for all layers, and over the first and final 5 episodes of training. \n",
    "Does Dropout affect gradient flow in your model? If so, how are the gradients affected?\n",
    "\n",
    "*Third*, without including Dropout, add batch normalisation to each hidden layer of your model.\n",
    "Again, compute and plot the mean and standard deviation of the gradients as you had done before. How is gradient flow affected by batch normalisation in your model?\n",
    "\n",
    "*Fourth*, using learning curves for training and validation data, show how batch normalisation affects the performance of your model, referring to its average performance on the test data as well as to the generalisation gap between the average training and validation learning curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform)\n",
    "\n",
    "num_validation_samples = 5000\n",
    "num_train_samples = len(train_data) - num_validation_samples\n",
    "\n",
    "train_data, val_data = random_split(train_data, [num_train_samples, num_validation_samples])\n",
    "\n",
    "print(len(train_data)) # 50000 training egs  \n",
    "print(len(val_data)) # 10000 test egs\n",
    "print(len(test_data)) # 10000 test egs\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 50\n",
    "learning_rate= 0.01\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "non_drop_model = BaselineNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = optim.SGD(non_drop_model.parameters(), lr=learning_rate)\n",
    "\n",
    "first_5_epochs_gradients_non_drop, last_5_epochs_gradients_non_drop = collect_gradients(non_drop_model, train_dataloader, device, criterion, optimiser, num_epochs)\n",
    "\n",
    "first_5_mean_gradients_non_drop, first_5_std_gradients_non_drop = compute_gradient_statistics(first_5_epochs_gradients_non_drop)\n",
    "last_5_mean_gradients_non_drop, last_5_std_gradients_non_drop = compute_gradient_statistics(last_5_epochs_gradients_non_drop)\n",
    "\n",
    "plot_gradient_statistics(first_5_mean_gradients_non_drop, first_5_std_gradients_non_drop, last_5_mean_gradients_non_drop, last_5_std_gradients_non_drop)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "drop_model = DropoutNet(0.6)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = optim.SGD(drop_model.parameters(), lr=learning_rate)\n",
    "\n",
    "first_5_epochs_gradients_dropout, last_5_epochs_gradients_dropout = collect_gradients(drop_model, train_dataloader, device, criterion, optimiser, num_epochs)\n",
    "\n",
    "first_5_mean_gradients_dropout, first_5_std_gradients_dropout = compute_gradient_statistics(first_5_epochs_gradients_dropout)\n",
    "last_5_mean_gradients_dropout, last_5_std_gradients_dropout = compute_gradient_statistics(last_5_epochs_gradients_dropout)\n",
    "\n",
    "plot_gradient_statistics(first_5_mean_gradients_dropout, first_5_std_gradients_dropout, last_5_mean_gradients_dropout, last_5_std_gradients_dropout)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "bn_model = BatchNormNet()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = optim.SGD(bn_model.parameters(), lr=learning_rate)\n",
    "\n",
    "first_5_epochs_gradients_bn, last_5_epochs_gradients_bn = collect_gradients(bn_model, train_dataloader, device, criterion, optimiser, num_epochs)\n",
    "\n",
    "first_5_mean_gradients_bn, first_5_std_gradients_bn = compute_gradient_statistics(first_5_epochs_gradients_bn)\n",
    "last_5_mean_gradients_bn, last_5_std_gradients_bn = compute_gradient_statistics(last_5_epochs_gradients_bn)\n",
    "\n",
    "plot_gradient_statistics(first_5_mean_gradients_bn, first_5_std_gradients_bn, last_5_mean_gradients_bn, last_5_std_gradients_bn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "random_seeds = list(range(5))\n",
    "\n",
    "\n",
    "path_to_save = f'./run_data/batch_norm/batch_norm_{num_epochs}_epochs.json'\n",
    "path_to_load = f'./run_data/batch_norm/batch_norm_{num_epochs}_epochs.json'\n",
    "\n",
    "averaged_results = {'bn':{}}\n",
    "\n",
    "save_experiment = True\n",
    "\n",
    "# train them both on the original data\n",
    "\n",
    "epoch_train_losses_by_run = []\n",
    "epoch_val_losses_by_run = []\n",
    "epoch_train_accuracies_by_run = []\n",
    "epoch_val_accuracies_by_run = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "reports = []\n",
    "\n",
    "for random_seed in random_seeds:\n",
    "    print('MODEL: ', i) \n",
    "    print('seed:', random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    model = BatchNormNet()\n",
    "    model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimiser = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    model, train_epoch_losses, train_epoch_accuracy, val_epoch_losses, val_epoch_accuracy, _,_ = run_training_and_validation(model, device, learning_rate, num_epochs, criterion, optimiser, train_dataloader, val_dataloader, metrics = False, manual_lr_schedule=False)\n",
    "    epoch_train_losses_by_run.append(train_epoch_losses)\n",
    "    epoch_val_losses_by_run.append(val_epoch_losses)\n",
    "    epoch_train_accuracies_by_run.append(train_epoch_accuracy)\n",
    "    epoch_val_accuracies_by_run.append(val_epoch_accuracy)\n",
    "    \n",
    "    test_loss, test_accuracy, report = run_testing(model, device, criterion, test_dataloader)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    reports.append(report)\n",
    "    \n",
    "average_train_losses = [sum(epoch_losses) / len(epoch_losses) for epoch_losses in zip(*epoch_train_losses_by_run)]\n",
    "average_val_losses = [sum(epoch_losses) / len(epoch_losses) for epoch_losses in zip(*epoch_val_losses_by_run)]\n",
    "average_train_accuracies = [sum(epoch_accuracies) / len(epoch_accuracies) for epoch_accuracies in zip(*epoch_train_accuracies_by_run)]\n",
    "average_val_accuracies =  [sum(epoch_accuracies) / len(epoch_accuracies) for epoch_accuracies in zip(*epoch_val_accuracies_by_run)]\n",
    "average_test_loss = sum(test_losses)/len(test_losses)\n",
    "average_test_accuracy = sum(test_accuracies)/len(test_accuracies)\n",
    "\n",
    "averaged_results['bn'] = {'seeds':random_seeds,'av_train_losses': average_train_losses,\n",
    "                                    'av_val_losses': average_val_losses,\n",
    "                                    'av_train_acc': average_train_accuracies,\n",
    "                                    'av_val_acc': average_val_accuracies,\n",
    "                                    'all_train_losses':epoch_train_losses_by_run,\n",
    "                                    'all_val_losses': epoch_val_losses_by_run,\n",
    "                                    'all_train_accuracies': epoch_train_accuracies_by_run,\n",
    "                                    'all_val_accuracies': epoch_val_accuracies_by_run,\n",
    "                                    'all_test_losses':test_losses, \n",
    "                                    'all_test_accuracies':test_accuracies,\n",
    "                                    'av_test_loss': average_test_loss,\n",
    "                                    'av_test_accuracy':average_test_accuracy}\n",
    "print('average for ')\n",
    "print('Model: ', i) \n",
    "plot_single_train_val_smoothed(average_train_losses,average_val_losses,average_train_accuracies,average_val_accuracies, num_epochs, smoothing_window=3, title=f'MODEL: {i}')\n",
    "\n",
    "    \n",
    "if save_experiment:\n",
    "    with open(path_to_save, 'w') as file:\n",
    "        json.dump(averaged_results, file, indent=4)  # 'indent' makes the output formatted and easier to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "a\n",
      "2\n",
      "b\n",
      "3\n",
      "c\n",
      "4\n",
      "d\n",
      "5\n",
      "e\n"
     ]
    }
   ],
   "source": [
    "for a, b in enumerate(['a', 'b', 'c', 'd', 'e'], 1):\n",
    "    print(a)\n",
    "    print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
