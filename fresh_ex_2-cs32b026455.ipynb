{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import json\n",
    "import importlib\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    from IPython import get_ipython\n",
    "    if 'IPKernelApp' not in get_ipython().config:  # Not in a notebook\n",
    "        from tqdm import tqdm\n",
    "    else:  # In a notebook\n",
    "        from tqdm.notebook import tqdm\n",
    "except ImportError:  # IPython is not installed\n",
    "    from tqdm import tqdm\n",
    "import utils\n",
    "from utils import *\n",
    "\n",
    "# importlib.reload(utils)\n",
    "\n",
    "\n",
    "# 2. set up for using GPU if available (with printed confirmation)  \n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "# 3. checking environment \n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False, transform=transform)\n",
    "\n",
    "num_validation_samples = 25000\n",
    "num_train_samples = len(train_data) - num_validation_samples\n",
    "train_data, val_data = random_split(train_data, [num_train_samples, num_validation_samples])\n",
    "\n",
    "print(len(train_data)) # 50000 training egs  \n",
    "print(len(val_data)) # 10000 test egs\n",
    "print(len(test_data)) # 10000 test egs\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 explore dropout rates\n",
    "\n",
    "num_epochs = 50\n",
    "learning_rate = 0.05\n",
    "\n",
    "random_seeds = list(range(1, 6))\n",
    "dropout_rates_for_experiment = [0, 0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "averaged_results = {dr:{} for dr in dropout_rates_for_experiment}\n",
    "\n",
    "path_to_save = f'./run_data/dropout/final_dropout_rate_compatison_lr_{learning_rate}_{num_epochs}_epochs.json'\n",
    "path_to_load = f'./run_data/dropout/final_dropout_rate_compatison_lr_{learning_rate}_{num_epochs}_epochs.json'\n",
    "save_experiment = True\n",
    "\n",
    "\n",
    "for dropout_rate in dropout_rates_for_experiment:\n",
    "    print('DR: ', dropout_rate) \n",
    "    epoch_train_losses_by_run = []\n",
    "    epoch_val_losses_by_run = []\n",
    "    epoch_train_accuracies_by_run = []\n",
    "    epoch_val_accuracies_by_run = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    reports = []\n",
    "    \n",
    "    for random_seed in random_seeds:\n",
    "        print('DR: ', dropout_rate) \n",
    "        print('seed:', random_seed)\n",
    "        torch.manual_seed(random_seed)\n",
    "        \n",
    "        model = DropoutNet(dropout_rate).to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimiser = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "        model, train_epoch_losses, train_epoch_accuracy, val_epoch_losses, val_epoch_accuracy, _,_ = run_training_and_validation(model, device, learning_rate, num_epochs, criterion, optimiser, train_dataloader, val_dataloader, metrics = False, manual_lr_schedule=False, plot=True)\n",
    "        epoch_train_losses_by_run.append(train_epoch_losses)\n",
    "        epoch_val_losses_by_run.append(val_epoch_losses)\n",
    "        epoch_train_accuracies_by_run.append(train_epoch_accuracy)\n",
    "        epoch_val_accuracies_by_run.append(val_epoch_accuracy)\n",
    "        \n",
    "        test_loss, test_accuracy, report = run_testing(model, device, criterion, test_dataloader)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        reports.append(report)\n",
    "        \n",
    "    average_train_losses = [sum(epoch_losses) / len(epoch_losses) for epoch_losses in zip(*epoch_train_losses_by_run)]\n",
    "    average_val_losses = [sum(epoch_losses) / len(epoch_losses) for epoch_losses in zip(*epoch_val_losses_by_run)]\n",
    "    average_train_accuracies = [sum(epoch_accuracies) / len(epoch_accuracies) for epoch_accuracies in zip(*epoch_train_accuracies_by_run)]\n",
    "    average_val_accuracies =  [sum(epoch_accuracies) / len(epoch_accuracies) for epoch_accuracies in zip(*epoch_val_accuracies_by_run)]\n",
    "    average_test_loss = sum(test_losses)/len(test_losses)\n",
    "    average_test_accuracy = sum(test_accuracies)/len(test_accuracies)\n",
    "    \n",
    "    averaged_results[dropout_rate] = {'seeds':random_seeds,'av_train_losses': average_train_losses,\n",
    "                                       'av_val_losses': average_val_losses,\n",
    "                                       'av_train_acc': average_train_accuracies,\n",
    "                                       'av_val_acc': average_val_accuracies,\n",
    "                                       'all_train_losses':epoch_train_losses_by_run,\n",
    "                                       'all_val_losses': epoch_val_losses_by_run,\n",
    "                                       'all_train_accuracies': epoch_train_accuracies_by_run,\n",
    "                                       'all_val_accuracies': epoch_val_accuracies_by_run,\n",
    "                                       'all_test_losses':test_losses, \n",
    "                                       'all_test_accuracies':test_accuracies,\n",
    "                                       'av_test_loss': average_test_loss,\n",
    "                                       'av_test_accuracy':average_test_accuracy}\n",
    "    print('average for ')\n",
    "    print('DR: ', dropout_rate) \n",
    "    plot_single_train_val_smoothed(average_train_losses,average_val_losses,average_train_accuracies,average_val_accuracies, num_epochs, smoothing_window=3, title=f'DROPOUT: {dropout_rate}')\n",
    "\n",
    "if save_experiment:\n",
    "    with open(path_to_save, 'w') as file:\n",
    "        json.dump(averaged_results, file, indent=4)  # 'indent' makes the output formatted and easier to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropout_data = path_to_load\n",
    "plot_all_models_performance_from_disk(dropout_data, enforce_axis=True)\n",
    "plot_performance_comparison_from_file(dropout_data, enforce_axis=True)\n",
    "display_accuracy_heatmap(dropout_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 2 - TRANSFER LEARNINNG DATA\n",
    "# To swap the datasets between the two dataloaders\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "original_train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "original_val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "swapped_train_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "swapped_val_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the non-dropout model (like inialise it fresh)\n",
    "# train them on original data and save them as model\n",
    "\n",
    "# train and save models ready for \n",
    "\n",
    "best_dropout_rate = 'x'\n",
    "\n",
    "num_epochs = 100\n",
    "learning_rate = 0.1\n",
    "\n",
    "random_seeds = list(range(1, 6))\n",
    "\n",
    "\n",
    "path_to_save = f'./run_data/dropout/corrected_dropout_model_comparison_original_data_{num_epochs}_epochs_lr_{learning_rate}.json'\n",
    "path_to_load = f'./run_data/dropout/corrected_dropout_model_comparison_original_data_{num_epochs}_epochs_lr_{learning_rate}.json'\n",
    "\n",
    "models = [0, 1]\n",
    "averaged_results = {i:{} for i in models}\n",
    "\n",
    "save_experiment = True\n",
    "\n",
    "# train them both on the original data\n",
    "for i, model in enumerate(models):\n",
    "    epoch_train_losses_by_run = []\n",
    "    epoch_val_losses_by_run = []\n",
    "    epoch_train_accuracies_by_run = []\n",
    "    epoch_val_accuracies_by_run = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    reports = []\n",
    "    \n",
    "    for random_seed in random_seeds:\n",
    "        print('MODEL: ', i) \n",
    "        print('seed:', random_seed)\n",
    "        torch.manual_seed(random_seed)\n",
    "        \n",
    "        model = BaselineNet() if i == 0 else DropoutNet(dropout_rate=best_dropout_rate)\n",
    "        model.to(device)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimiser = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "        \n",
    "        model, train_epoch_losses, train_epoch_accuracy, val_epoch_losses, val_epoch_accuracy, _,_ = run_training_and_validation(model, device, learning_rate, num_epochs, criterion, optimiser, original_train_dataloader, original_val_dataloader, metrics = False, manual_lr_schedule=False, plot=True)\n",
    "        epoch_train_losses_by_run.append(train_epoch_losses)\n",
    "        epoch_val_losses_by_run.append(val_epoch_losses)\n",
    "        epoch_train_accuracies_by_run.append(train_epoch_accuracy)\n",
    "        epoch_val_accuracies_by_run.append(val_epoch_accuracy)\n",
    "        \n",
    "        test_loss, test_accuracy, report = run_testing(model, device, criterion, test_dataloader)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        reports.append(report)\n",
    "        \n",
    "    average_train_losses = [sum(epoch_losses) / len(epoch_losses) for epoch_losses in zip(*epoch_train_losses_by_run)]\n",
    "    average_val_losses = [sum(epoch_losses) / len(epoch_losses) for epoch_losses in zip(*epoch_val_losses_by_run)]\n",
    "    average_train_accuracies = [sum(epoch_accuracies) / len(epoch_accuracies) for epoch_accuracies in zip(*epoch_train_accuracies_by_run)]\n",
    "    average_val_accuracies =  [sum(epoch_accuracies) / len(epoch_accuracies) for epoch_accuracies in zip(*epoch_val_accuracies_by_run)]\n",
    "    average_test_loss = sum(test_losses)/len(test_losses)\n",
    "    average_test_accuracy = sum(test_accuracies)/len(test_accuracies)\n",
    "    \n",
    "    averaged_results[i] = {'seeds':random_seeds,'av_train_losses': average_train_losses,\n",
    "                                       'av_val_losses': average_val_losses,\n",
    "                                       'av_train_acc': average_train_accuracies,\n",
    "                                       'av_val_acc': average_val_accuracies,\n",
    "                                       'all_train_losses':epoch_train_losses_by_run,\n",
    "                                       'all_val_losses': epoch_val_losses_by_run,\n",
    "                                       'all_train_accuracies': epoch_train_accuracies_by_run,\n",
    "                                       'all_val_accuracies': epoch_val_accuracies_by_run,\n",
    "                                       'all_test_losses':test_losses, \n",
    "                                       'all_test_accuracies':test_accuracies,\n",
    "                                       'av_test_loss': average_test_loss,\n",
    "                                       'av_test_accuracy':average_test_accuracy}\n",
    "    print('average for ')\n",
    "    print('Model: ', i) \n",
    "    plot_single_train_val_smoothed(average_train_losses,average_val_losses,average_train_accuracies,average_val_accuracies, num_epochs, smoothing_window=3, title=f'PRETRAINING MODEL: {i}')\n",
    "    \n",
    "    # save last version of model to disk for retraining    \n",
    "    torch.save(model, f'./models/trained_model_{i}.pth')\n",
    "\n",
    "    \n",
    "if save_experiment:\n",
    "    with open(path_to_save, 'w') as file:\n",
    "        json.dump(averaged_results, file, indent=4)  # 'indent' makes the output formatted and easier to read\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_training_data = path_to_load\n",
    "plot_all_models_performance_from_disk(pre_training_data, enforce_axis=True)\n",
    "plot_performance_comparison_from_file(pre_training_data, enforce_axis=True)\n",
    "display_accuracy_heatmap(pre_training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD THEM AS NEW MODELS FOR RETRAINING \n",
    "\n",
    "pretrained_model_non_dropout = torch.load('./models/trained_model_0.pth', pretrained=True)\n",
    "pretrained_model_best_dropout = torch.load('./models/trained_model_1.pth', pretrained=True)\n",
    "\n",
    "\n",
    "pretrained_model_non_dropout.fc1 =  nn.Linear(in_features=64 * 4 * 4, out_features=64)\n",
    "pretrained_model_best_dropout.fc1 =  nn.Linear(in_features=64 * 4 * 4, out_features=64)\n",
    "\n",
    "\n",
    "pretrained_model_non_dropout.fc2 = nn.Linear(in_features=64, out_features=10)\n",
    "pretrained_model_best_dropout.fc2 = nn.Linear(in_features=64, out_features=10)\n",
    "\n",
    "# do transfer learning\n",
    "\n",
    "num_epochs = 50\n",
    "learning_rate = 0.1\n",
    "random_seeds = list(range(1,6))\n",
    "\n",
    "averaged_results = {dr:{} for dr in dropout_rates_for_experiment}\n",
    "\n",
    "path_to_save = f'./run_data/dropout/corrected_dropout_model_comparison_swapped_data_{num_epochs}_epochs_lr_{learning_rate}.json'\n",
    "path_to_load = f'./run_data/dropout/corrected_dropout_model_comparison_swapped_data_{num_epochs}_epochs_lr_{learning_rate}.json'\n",
    "\n",
    "models = [0, 1]\n",
    "averaged_results = {i:{} for i in models}\n",
    "\n",
    "save_experiment = True\n",
    "\n",
    "# train them both on the swapped train and val data - test data same\n",
    "for i, model in enumerate(models):\n",
    "    epoch_train_losses_by_run = []\n",
    "    epoch_val_losses_by_run = []\n",
    "    epoch_train_accuracies_by_run = []\n",
    "    epoch_val_accuracies_by_run = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    reports = []\n",
    "    \n",
    "    for random_seed in random_seeds:\n",
    "        print('MODEL: ', i) \n",
    "        print('seed:', random_seed)\n",
    "        model = pretrained_model_non_dropout if i == 0 else pretrained_model_best_dropout\n",
    "        model.to(device)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimiser = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "        model, train_epoch_losses, train_epoch_accuracy, val_epoch_losses, val_epoch_accuracy, _,_ = run_training_and_validation(model, device, learning_rate, num_epochs, criterion, optimiser, swapped_train_dataloader, swapped_val_dataloader, metrics = False, manual_lr_schedule=False, plot=True)\n",
    "        epoch_train_losses_by_run.append(train_epoch_losses)\n",
    "        epoch_val_losses_by_run.append(val_epoch_losses)\n",
    "        epoch_train_accuracies_by_run.append(train_epoch_accuracy)\n",
    "        epoch_val_accuracies_by_run.append(val_epoch_accuracy)\n",
    "        \n",
    "        test_loss, test_accuracy, report = run_testing(model, device, criterion, test_dataloader)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_accuracy)\n",
    "        reports.append(report)\n",
    "        \n",
    "    average_train_losses = [sum(epoch_losses) / len(epoch_losses) for epoch_losses in zip(*epoch_train_losses_by_run)]\n",
    "    average_val_losses = [sum(epoch_losses) / len(epoch_losses) for epoch_losses in zip(*epoch_val_losses_by_run)]\n",
    "    average_train_accuracies = [sum(epoch_accuracies) / len(epoch_accuracies) for epoch_accuracies in zip(*epoch_train_accuracies_by_run)]\n",
    "    average_val_accuracies =  [sum(epoch_accuracies) / len(epoch_accuracies) for epoch_accuracies in zip(*epoch_val_accuracies_by_run)]\n",
    "    average_test_loss = sum(test_losses)/len(test_losses)\n",
    "    average_test_accuracy = sum(test_accuracies)/len(test_accuracies)\n",
    "    \n",
    "    averaged_results[i] = {'seeds':random_seeds,'av_train_losses': average_train_losses,\n",
    "                                       'av_val_losses': average_val_losses,\n",
    "                                       'av_train_acc': average_train_accuracies,\n",
    "                                       'av_val_acc': average_val_accuracies,\n",
    "                                       'all_train_losses':epoch_train_losses_by_run,\n",
    "                                       'all_val_losses': epoch_val_losses_by_run,\n",
    "                                       'all_train_accuracies': epoch_train_accuracies_by_run,\n",
    "                                       'all_val_accuracies': epoch_val_accuracies_by_run,\n",
    "                                       'all_test_losses':test_losses, \n",
    "                                       'all_test_accuracies':test_accuracies,\n",
    "                                       'av_test_loss': average_test_loss,\n",
    "                                       'av_test_accuracy':average_test_accuracy}\n",
    "    print('average for ')\n",
    "    print('Model: ', i) \n",
    "    plot_single_train_val_smoothed(average_train_losses,average_val_losses,average_train_accuracies,average_val_accuracies, num_epochs, smoothing_window=3, title=f'TRANSFER LEARNING MODEL: {i}')\n",
    "    \n",
    "\n",
    "\n",
    "if save_experiment:\n",
    "    with open(path_to_save, 'w') as file:\n",
    "        json.dump(averaged_results, file, indent=4)  # 'indent' makes the output formatted and easier to read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_learned_data = path_to_load\n",
    "plot_all_models_performance_from_disk(transfer_learned_data, enforce_axis=True)\n",
    "plot_performance_comparison_from_file(transfer_learned_data, enforce_axis=True)\n",
    "display_accuracy_heatmap(transfer_learned_data)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
